<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Makefile]]></title>
    <url>%2F2018%2F12%2F19%2FMakefile%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[算法和数据结构-树]]></title>
    <url>%2F2018%2F12%2F18%2F%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%91%2F</url>
    <content type="text"><![CDATA[树的类别二叉树、二叉搜索树、平衡二叉树、红黑树、B树、B+树、字典树 二叉树二叉树，插入有序的数据，会退化成链表，需要调整数据均匀分布，保证平衡性(搜索效率)书的查找性能取决于树的高度 二叉搜索树(BST)平衡二叉树(AVL)windows对进程地址空间的管理用到了AVL树 红黑树广泛用在C++的STL中, 如map和set. B树多路搜索树，每个节点可以拥有多于两个孩子节点。M路的B树最多有用M个孩子节点。 设计成多路是为了降低树的高度，但是无限多路时退化成有序数组。一般用于文件索引，为什么不用红黑树和有序数组？文件系统和数据库的索引都是存在硬盘上的，并且如果数据量大的话，不一定能一次性加载到内存中。B树索引可以每次加载一个节点，一步一步往下找。在内存中黑红树比B树效率高，但涉及到磁盘，B树更优。 B+树在B树基础上进行改造，数据都在叶子结点，同时叶子结点之间用指针形成链表。 为什么要这样设计？这也是和业务场景相关的，数据库中select数据，不一定只选一条，很多时候会选多条，比如按照id排序后选10条。如果是多条的话，B树需要做局部的中序遍历，可能要跨层访问。而B+树由于所有数据都在叶子结点，不用跨层，同时由于有链表结构，只需要找到首尾，通过链表就能把所有数据取出来了。 选出7~19，在叶子节点中就可以找到。 字典树(Trie)用在统计和排序大量字符串，如自动机一个典型应用是前缀匹配，比如在我们输入时，搜索引擎会给予提示字典树]]></content>
      <categories>
        <category>算法和数据结构</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据库水平、垂直拆分]]></title>
    <url>%2F2018%2F12%2F18%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%B0%B4%E5%B9%B3%E3%80%81%E5%9E%82%E7%9B%B4%E6%8B%86%E5%88%86%2F</url>
    <content type="text"><![CDATA[水平、垂直分库]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[死锁和银行家算法]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%AD%BB%E9%94%81%E5%92%8C%E9%93%B6%E8%A1%8C%E5%AE%B6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[MD5加密算法]]></title>
    <url>%2F2018%2F12%2F01%2FMD5%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[什么是MD5加密算法MD5消息摘要算法是一种被广泛使用的密码散列函数, 属Hash算法一类, MD5算法对输入任意长度的消息进行运行，产生一个128位(16字节)的散列值(hash value)。 应用场景文件一致性验证MD5的典型应用是对一段信息（Message）产生信息摘要（Message-Digest），以防止被篡改。 1251_zjdev[/data01/zjgrp/zjdev/users/zhangbb]%md5sum test.cpp 731b8735653acd4c4cdbd05883fe90d1 test.cpp 数字签名MD5的典型应用是对一段Message(字节串)产生fingerprint(指纹），以防止被“篡改”。 算法原理以下所描述的消息长度、填充数据都以位(Bit)为单位，字节序为小端字节。 数据填充对消息进行数据填充，使消息的长度对512取模得448，设消息长度为X，即满足X mod 512=448。根据此公式得出需要填充的数据长度。填充方法：在消息后面进行填充，填充第一位为1，其余为0。 添加消息长度在第一步结果之后再填充上原消息的长度，可用来进行的存储长度为64位。如果消息长度大于264，则只使用其低64位的值，即（消息长度 对 264取模）。在此步骤进行完毕后，最终消息长度就是512的整数倍 数据处理准备需要用到的数据： 4个常数： A = 0x67452301, B = 0x0EFCDAB89, C = 0x98BADCFE, D = 0x10325476; 4个函数：F(X,Y,Z)=(X &amp; Y) | ((~X) &amp; Z); G(X,Y,Z)=(X &amp; Z) | (Y &amp; (~Z)); H(X,Y,Z)=X ^ Y ^ Z; I(X,Y,Z)=Y ^ (X | (~Z)); 把消息分以512位为一分组进行处理，每一个分组进行4轮变换，以上面所说4个常数为起始变量进行 计算，重新输出4个变量，以这4个变量再进行下一分组的运算，如果已经是最后一个分组，则这4个 变量为最后的结果，即MD5值。 具体计算的实现较为复杂，建议查阅相关书籍，下面给出在C++上的实现代码。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137#ifndef MD5H#define MD5H#include &lt;math.h&gt;#include &lt;Windows.h&gt;void ROL(unsigned int &amp;s, unsigned short cx); //32位数循环左移实现函数void ltob(unsigned int &amp;i); //B\L互转，接受UINT类型unsigned int* MD5(const char* mStr); //接口函数，并执行数据填充，计算MD5时调用此函数#endif#include &quot;MD5.h&quot;/*4组计算函数*/inline unsigned int F(unsigned int X, unsigned int Y, unsigned int Z)&#123; return (X &amp; Y) | ((~X) &amp; Z);&#125;inline unsigned int G(unsigned int X, unsigned int Y, unsigned int Z)&#123; return (X &amp; Z) | (Y &amp; (~Z));&#125;inline unsigned int H(unsigned int X, unsigned int Y, unsigned int Z)&#123; return X ^ Y ^ Z;&#125;inline unsigned int I(unsigned int X, unsigned int Y, unsigned int Z)&#123; return Y ^ (X | (~Z));&#125;/*4组计算函数结束*//*32位数循环左移实现函数*/void ROL(unsigned int &amp;s, unsigned short cx)&#123; if (cx &gt; 32)cx %= 32; s = (s &lt;&lt; cx) | (s &gt;&gt; (32 - cx)); return;&#125;/*B\L互转，接收UINT类型*/void ltob(unsigned int &amp;i)&#123; unsigned int tmp = i;//保存副本 byte *psour = (byte*)&amp;tmp, *pdes = (byte*)&amp;i; pdes += 3;//调整指针，准备左右调转 for (short i = 3; i &gt;= 0; --i) &#123; CopyMemory(pdes - i, psour + i, 1); &#125; return;&#125;/*MD5循环计算函数，label=第几轮循环（1&lt;=label&lt;=4），lGroup数组=4个种子副本，M=数据（16组32位数指针）种子数组排列方式: --A--D--C--B--，即 lGroup[0]=A; lGroup[1]=D; lGroup[2]=C; lGroup[3]=B;*/void AccLoop(unsigned short label, unsigned int *lGroup, void *M)&#123; unsigned int *i1, *i2, *i3, *i4, TAcc, tmpi = 0; //定义:4个指针； T表累加器； 局部变量 typedef unsigned int(*clac)(unsigned int X, unsigned int Y, unsigned int Z); //定义函数类型 const unsigned int rolarray[4][4] = &#123; &#123; 7, 12, 17, 22 &#125;, &#123; 5, 9, 14, 20 &#125;, &#123; 4, 11, 16, 23 &#125;, &#123; 6, 10, 15, 21 &#125; &#125;;//循环左移-位数表 const unsigned short mN[4][16] = &#123; &#123; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 &#125;, &#123; 1, 6, 11, 0, 5, 10, 15, 4, 9, 14, 3, 8, 13, 2, 7, 12 &#125;, &#123; 5, 8, 11, 14, 1, 4, 7, 10, 13, 0, 3, 6, 9, 12, 15, 2 &#125;, &#123; 0, 7, 14, 5, 12, 3, 10, 1, 8, 15, 6, 13, 4, 11, 2, 9 &#125; &#125;;//数据坐标表 const unsigned int *pM = static_cast&lt;unsigned int*&gt;(M);//转换类型为32位的Uint TAcc = ((label - 1) * 16) + 1; //根据第几轮循环初始化T表累加器 clac clacArr[4] = &#123; F, G, H, I &#125;; //定义并初始化计算函数指针数组 /*一轮循环开始（16组-&gt;16次）*/ for (short i = 0; i &lt; 16; ++i) &#123; /*进行指针自变换*/ i1 = lGroup + ((0 + i) % 4); i2 = lGroup + ((3 + i) % 4); i3 = lGroup + ((2 + i) % 4); i4 = lGroup + ((1 + i) % 4); /*第一步计算开始: A+F(B,C,D)+M[i]+T[i+1] 注:第一步中直接计算T表*/ tmpi = (*i1 + clacArr[label - 1](*i2, *i3, *i4) + pM[(mN[label - 1][i])] + (unsigned int)(0x100000000UL * abs(sin((double)(TAcc + i))))); ROL(tmpi, rolarray[label - 1][i % 4]);//第二步:循环左移 *i1 = *i2 + tmpi;//第三步:相加并赋值到种子 &#125; return;&#125;/*接口函数，并执行数据填充*/unsigned int* MD5(const char* mStr)&#123; unsigned int mLen = strlen(mStr); //计算字符串长度 if (mLen &lt; 0) return 0; unsigned int FillSize = 448 - ((mLen * 8) % 512); //计算需填充的bit数 unsigned int FSbyte = FillSize / 8; //以字节表示的填充数 unsigned int BuffLen = mLen + 8 + FSbyte; //缓冲区长度或者说填充后的长度 unsigned char *md5Buff = new unsigned char[BuffLen]; //分配缓冲区 CopyMemory(md5Buff, mStr, mLen); //复制字符串到缓冲区 /*数据填充开始*/ md5Buff[mLen] = 0x80; //第一个bit填充1 ZeroMemory(&amp;md5Buff[mLen + 1], FSbyte - 1); //其它bit填充0，另一可用函数为FillMemory unsigned long long lenBit = mLen * 8ULL; //计算字符串长度，准备填充 CopyMemory(&amp;md5Buff[mLen + FSbyte], &amp;lenBit, 8); //填充长度 /*数据填充结束*/ /*运算开始*/ unsigned int LoopNumber = BuffLen / 64; //以16个字为一分组，计算分组数量 unsigned int A = 0x67452301, B = 0x0EFCDAB89, C = 0x98BADCFE, D = 0x10325476;//初始4个种子，小端类型 unsigned int *lGroup = new unsigned int[4]&#123; A, D, C, B&#125;; //种子副本数组,并作为返回值返回 for (unsigned int Bcount = 0; Bcount &lt; LoopNumber; ++Bcount) //分组大循环开始 &#123; /*进入4次计算的小循环*/ for (unsigned short Lcount = 0; Lcount &lt; 4;) &#123; AccLoop(++Lcount, lGroup, &amp;md5Buff[Bcount * 64]); &#125; /*数据相加作为下一轮的种子或者最终输出*/ A = (lGroup[0] += A); B = (lGroup[3] += B); C = (lGroup[2] += C); D = (lGroup[1] += D); &#125; /*转换内存中的布局后才能正常显示*/ ltob(lGroup[0]); ltob(lGroup[1]); ltob(lGroup[2]); ltob(lGroup[3]); delete[] md5Buff; //清除内存并返回 return lGroup;&#125; 1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &quot;MD5.h&quot;int main(int argc, char **argv)&#123; char tmpstr[256], buf[4][10]; std::cout &lt;&lt; &quot;请输入要加密的字符串：&quot;; std::cin &gt;&gt; tmpstr; unsigned int* tmpGroup = MD5(tmpstr); sprintf_s(buf[0], &quot;%8X&quot;, tmpGroup[0]); sprintf_s(buf[1], &quot;%8X&quot;, tmpGroup[3]); sprintf_s(buf[2], &quot;%8X&quot;, tmpGroup[2]); sprintf_s(buf[3], &quot;%8X&quot;, tmpGroup[1]); std::cout &lt;&lt;&quot;MD5:&quot;&lt;&lt; buf[0] &lt;&lt; buf[1] &lt;&lt; buf[2] &lt;&lt; buf[3] &lt;&lt; std::endl; delete[] tmpGroup; return 0; //在此下断点才能看到输出的值&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[c++11特性]]></title>
    <url>%2F2018%2F11%2F28%2Fc-11%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[语法糖关键字auto auto声明的变量必须要初始化，否则编译器不能判断变量的类型auto不能被声明为返回值，auto不能作为形参，auto不能被修饰为模板参数不会影响编译、运行效果 decltype类型指示符123int a = 1;int&amp; b = a;decltype(a) c = 2; nullptr 空指针, 类型是指针, 主要用于重载 function123456789101112131415161718192021222324#include &lt;functional&gt;int add(int a, int b)&#123; return a+b;&#125;class Add&#123; public: int operator()(int x,int y) &#123; return x+y; &#125;&#125;;int main()&#123; function&lt;int(int, int)&gt; f1 = add; // 函数 function&lt;int(int, int)&gt; f2 = Add(); // 类对象 function&lt;int(int, int)&gt; f2 = [](int a, int b)&#123; return a+b; &#125;; //lambda表达式 cout&lt;&lt; f1(a,b) &lt;&lt; f2(a,b) &lt;&lt; f3(a,b) &lt;&lt; endl;&#125; 范围for语句123456789vector&lt;int&gt; vct&#123;1,2,3,4,5&#125;;for(auto &amp;num : vct)&#123; num +1;&#125;for(auto num : vct)&#123; cout&lt;&lt; num &lt;&lt; endl;&#125; lambda表达式 text [ capture ] ( params ) mutable exception attribute -&gt; ret { body } [ capture ] ( params ) -&gt; ret { body } [ capture ] ( params ) { body } [ capture ] { body } [ capture ] desc [a,&amp;b] a变量以值的方式呗捕获，b以引用的方式被捕获 [this] 以值的方式捕获 this 指针 [&amp;] 以引用的方式捕获所有的外部自动变量 [=] 以值的方式捕获所有的外部自动变量 [] 不捕获外部的任何变量 123456int main()&#123; int boys=4, girls=3; auto totalChild = [=]()-&gt;int&#123;return boys+grils;&#125;; cout&lt;&lt; totalChild() &lt;&lt; endl;&#125; 右值引用：移动语义与完美转发有指针成员的类，拷贝构造时，会浪费资源。因此引入了移动语义。1234567891011121314&#123;a = b + c;# 等号左边是左值，等号右边是右值# 可以取地址,有名字的就是左值(&amp;a)，反之就是右值(a+b)&#125;MyString(MyString&amp;&amp; str) &#123; std::cout &lt;&lt; &quot;Move Ctor source from &quot; &lt;&lt; str._data &lt;&lt; endl; _len = str._len; _data = str._data; str._len = 0; str._data = NULL;&#125; std::movestl容器智能指针线程]]></content>
      <categories>
        <category>c++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Big-O]]></title>
    <url>%2F2018%2F11%2F26%2FBig-O%2F</url>
    <content type="text"><![CDATA[from web]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[开源库应用--UnitTest++]]></title>
    <url>%2F2018%2F11%2F21%2F%E5%BC%80%E6%BA%90%E5%BA%93%E5%BA%94%E7%94%A8-UnitTest%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[开源库应用--sqlite3]]></title>
    <url>%2F2018%2F11%2F21%2F%E5%BC%80%E6%BA%90%E5%BA%93%E5%BA%94%E7%94%A8-sqlite3%2F</url>
    <content type="text"><![CDATA[SQLite 是一个软件库，实现了自给自足的、无服务器的、零配置的、事务性的 SQL 数据库引擎。 教程]]></content>
      <categories>
        <category>3rd</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[开源库应用--tcmalloc]]></title>
    <url>%2F2018%2F11%2F21%2F%E5%BC%80%E6%BA%90%E5%BA%93%E5%BA%94%E7%94%A8-tcmalloc%2F</url>
    <content type="text"><![CDATA[tcmalloctcmalloc是一个内存分配器，管理堆内存，主要影响malloc和free，用于降低频繁分配、释放内存造成的损耗,并且有效的控制内存碎片。 解决了什么问题实现原理]]></content>
      <categories>
        <category>3rd</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[开源库应用--libevent]]></title>
    <url>%2F2018%2F11%2F21%2F%E5%BC%80%E6%BA%90%E5%BA%93%E5%BA%94%E7%94%A8-libevent%2F</url>
    <content type="text"></content>
      <categories>
        <category>3rd</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[开源库应用--boost]]></title>
    <url>%2F2018%2F11%2F21%2F%E5%BC%80%E6%BA%90%E5%BA%93%E5%BA%94%E7%94%A8-boost%2F</url>
    <content type="text"></content>
      <categories>
        <category>3rd</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分布式存储简介]]></title>
    <url>%2F2018%2F11%2F21%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[nginx功能简介]]></title>
    <url>%2F2018%2F11%2F20%2Fnginx%E5%8A%9F%E8%83%BD%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Nginx功能 反向代理 负载均衡 HTTP服务器 正向代理 反向代理负载均衡HTTP服务器正向代理]]></content>
      <categories>
        <category>web</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[fork/vfork/clone]]></title>
    <url>%2F2018%2F11%2F20%2Ffork-vfork-clone%2F</url>
    <content type="text"></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[c++关键字]]></title>
    <url>%2F2018%2F11%2F19%2Fc-%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[volatile作用 volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素（操作系统、硬件、其它线程等）更改。所以使用 volatile 告诉编译器不应对这样的对象进行优化。 volatile 关键字声明的变量，每次访问时都必须从内存中取出值（没有被 volatile 修饰的变量，可能由于编译器的优化，从 CPU 寄存器中取值） const 可以是 volatile （如只读的状态寄存器） 指针可以是 volatile 应用场景并行设备的硬件寄存器（如状态寄存器）12 一个中断服务子程序中访问到的变量12 多线程共享变量12 其他12 explicitextern 被 extern 限定的函数或变量是 extern 类型的 被 extern “C” 修饰的变量和函数是按照 C 语言方式编译和连接的 typedefconst]]></content>
      <categories>
        <category>c++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[c++函数指针]]></title>
    <url>%2F2018%2F11%2F19%2Fc-%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%2F</url>
    <content type="text"><![CDATA[函数名到底是什么东西呢？ 常用函数调用1234567891011121314#include &lt;iostream&gt;using namespace std;void Func(int a); // void Func(int); 声明int main()&#123; Func(5); return 0;&#125;void Func(int a)&#123; cout&lt;&lt; &quot;a=&quot; &lt;&lt; a &lt;&lt;endl;&#125; 函数指针变量的声明和使用1234567891011121314151617181920212223242526#include &lt;iostream&gt;using namespace std;void Func(int a); // 或void Func(int);void (*FuncP)(int); // 或void (*FuncP)(int a);int main()&#123; Func(5); (*Func)(5); // 一般不这样写 FuncP = &amp;Func; (*FuncP)(5); FuncP(5); FuncP = Func; FuncP(5); return 0;&#125;void Func(int a)&#123; cout&lt;&lt; &quot;a=&quot; &lt;&lt; a &lt;&lt;endl;&#125; 为了书写与数学函数形式一样方便, C语言的设计者允许如下操作: FuncP 和 Func是一样的，都是函数指针 (*Func)(5) = Func(5), 与数学函数形式一样 FunP函数指针变量也可以FunP(10)的形式来调用 赋值时，即可FunP=&amp;Func形式，也可FunP=MyFun 定义函数的指针类型1234567891011121314151617#include &lt;iostream&gt;using namespace std;typedef int* INTP; // 定义一个类型void Func(int a); // 声明一个函数typedef void (*FuncType)(int); // 定义一个函数指针类型FuncType FuncP; // 声明一个函数指针变量int main()&#123; FuncP = Func; FuncP(5); return 0;&#125;void Func(int a)&#123; cout&lt;&lt; &quot;a=&quot; &lt;&lt; a &lt;&lt;endl;&#125; 函数指针作为参数1234567891011121314151617181920#include &lt;iostream&gt;using namespace std; void Func(int a); typedef void (*FuncType)(int); int int CallFunc(FuncType p, int);(FuncType p, int a);int main()&#123; CallFunc(Func, 5); return 0;&#125;void Func(int a)&#123; cout&lt;&lt; &quot;a=&quot; &lt;&lt; a &lt;&lt;endl;&#125;int CallFunc(FuncType p, int)&#123; p(a);&#125; 地址跳转1(*(void (*)(void))(0x30700000))(); (void ()(void)) 转化为一个函数指针fp, 上面表达式同 (fp)()]]></content>
      <categories>
        <category>c++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[c++实现final]]></title>
    <url>%2F2018%2F11%2F19%2Fc-%E5%AE%9E%E7%8E%B0final%2F</url>
    <content type="text"><![CDATA[有时候我们希望一个类不能被继承，这种类称为final类，一个类如果有一个虚拟私有继承的基类，那么该类不能被继承。在C++11标准之前要实现这种技术，需要巧妙地利用一些细节首先我们要明确以下几点： 类的构造函数或析析构函数声明为私有的，那么该类不能被继承，但同时该类也不能使用派生类只能访问基类的公有成员和保护成员，如果是私有继承，基类中所有成员到子类中将成为私有的，子类的派生类也即子类的子类只能访问其直接父类的公有成员或保护成员，不能访问最原始基类的任何成员虚继承时, 由最终子类构造基类 123456789101112class FinalBase&#123;protected: //FinalBase()&#123;&#125; //~FinalBase()&#123;&#125;&#125;;class Filal : virtual private FinalBase&#123;public: Filal() &#123; cout&lt;&lt;&quot;final class.&quot;&lt;&lt;endl; &#125;&#125;; Final 就是一个final类, 不能被继承。gcc4.7以前有些版本编译器需要声明保护的基类构造或析构。 在C++11标准中，引入了final关键字，实现就简单多了。 123class Test final&#123;&#125;]]></content>
      <categories>
        <category>c++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[c++菱形继承]]></title>
    <url>%2F2018%2F11%2F19%2Fc-%E8%8F%B1%E5%BD%A2%E7%BB%A7%E6%89%BF%2F</url>
    <content type="text"><![CDATA[菱形继承是什么封装，继承，多态，这是C++语言的三大特性，而每次在谈到继承时不可避免的要谈到一个问题：菱形继承 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;using namespace std;class Base&#123;public: Base() &#123; cout&lt;&lt;&quot;Base&quot;&lt;&lt;endl; &#125; ~Base() &#123; cout&lt;&lt;&quot;~Base&quot;&lt;&lt;endl; &#125; void show()&#123; cout &lt;&lt; &quot;Base::show a=&quot; &lt;&lt; a &lt;&lt; endl; &#125; int a=0;&#125;;class A : public Base&#123;public: A() &#123; cout&lt;&lt;&quot;A&quot;&lt;&lt;endl; &#125; ~A() &#123; cout&lt;&lt;&quot;~A&quot;&lt;&lt;endl; &#125;&#125;;class B : public Base&#123;public: B() &#123; cout&lt;&lt;&quot;B&quot;&lt;&lt;endl; &#125; ~B() &#123; cout&lt;&lt;&quot;~B&quot;&lt;&lt;endl; &#125;&#125;;class C : public A, public B&#123;public: C() &#123; cout&lt;&lt;&quot;C&quot;&lt;&lt;endl; &#125; ~C() &#123; cout&lt;&lt;&quot;~C&quot;&lt;&lt;endl; &#125;&#125;;int main()&#123; C c; cout&lt;&lt; &quot;sizeof(Base)=&quot;&lt;&lt; sizeof(Base) &lt;&lt; endl; cout&lt;&lt; &quot;sizeof(C)=&quot;&lt;&lt; sizeof(c) &lt;&lt; endl;&#125;// output: BaseABaseBCsizeof(Base)=4sizeof(C)=8~C~B~Base~A~Base 从输出结果来看, 构造顺序按声明的顺序，C类的大小8是有2个Base对象。当用C对象调用show方法，会产生“二义性”问题。 域限定方式可解决：12C c;c.A::show(); 还有就可以使用虚继承的方式 虚继承虚继承是一种机制，类通过虚继承指出它希望共享虚基类的状态。对给定的虚基类，无论该类在派生层次中作为虚基类出现多少次，只继承一个共享的基类子对象，共享基类子对象称为虚基类。虚基类用virtual声明继承关系就行了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;using namespace std;class Base&#123;public: Base() &#123; cout&lt;&lt;&quot;Base&quot;&lt;&lt;endl; &#125; ~Base() &#123; cout&lt;&lt;&quot;~Base&quot;&lt;&lt;endl; &#125; void show()&#123; cout &lt;&lt; &quot;Base::show a=&quot; &lt;&lt; a &lt;&lt; endl; &#125; int a=0;&#125;;class A : virtual public Base&#123;public: A() &#123; cout&lt;&lt;&quot;A&quot;&lt;&lt;endl; &#125; ~A() &#123; cout&lt;&lt;&quot;~A&quot;&lt;&lt;endl; &#125;&#125;;class B : virtual public Base&#123;public: B() &#123; cout&lt;&lt;&quot;B&quot;&lt;&lt;endl; &#125; ~B() &#123; cout&lt;&lt;&quot;~B&quot;&lt;&lt;endl; &#125;&#125;;class C : public A, public B&#123;public: C() &#123; cout&lt;&lt;&quot;C&quot;&lt;&lt;endl; &#125; ~C() &#123; cout&lt;&lt;&quot;~C&quot;&lt;&lt;endl; &#125;&#125;;int main()&#123; C c; cout&lt;&lt; &quot;sizeof(Base)=&quot;&lt;&lt; sizeof(Base) &lt;&lt; endl; cout&lt;&lt; &quot;sizeof(C)=&quot;&lt;&lt; sizeof(c) &lt;&lt; endl;&#125;// output:BaseABCsizeof(Base)=4sizeof(C)=24~C~B~A~Base 输出24 = (2个8字节的C类虚基指针) + sizeof(A)+sizeof(B) = 16 + 4 + 4 典型应用123class istream : virtual public ios&#123;...&#125;;class ostream : virtual public ios&#123;...&#125;;class iostream : public istream, public ostream&#123;...&#125;; 注意 虚继承只是解决了菱形继承中派生类多个基类内存拷贝的问题，并没有解决多重继承的二义性问题 通常每个类只会初始化自己的直接基类，如果不按虚继承处理，那么在菱形继承中会出现基类被初始多次的情况。在虚继承中，对初始化进行了特殊处理，由最底层派生类的构造函数初始化虚基类]]></content>
      <categories>
        <category>c++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[个人能力总结]]></title>
    <url>%2F2018%2F11%2F16%2F%E4%B8%AA%E4%BA%BA%E8%83%BD%E5%8A%9B%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[优缺点阐述，也作为个人能力提升的计划。 决策能力决策正确与错误, 会达到、超出、背离预期结果，需要提升分析和判断能力。 时间管理合理安排和利用时间，提高工作效率。工作繁琐, 测试问题，需求讨论，代码开发，一天都很忙碌.掌握工作流程，讲究方法。QA：描述清楚背景和目的，很多时候就是低级的配置问题。discuss：不必要的讨论不参加dev：先文档后代码，理清思路，高质量，少bug。 沟通能力简单说先得搞明白对方意思。耐心观察和聆听，从对方表情和言语了解对方思路，再有效沟通。情绪化的负作用很大，影响沟通效果，在突发事件无法分析和决断，最终使工作开展困难。QA：”让我测这测那，我TMD不测了!”, “还没解决，快点快点!”PSO：””DEV：”你们改是最合理的!” “太复杂，影响太大，改不了！”CUST：”为什么不能支持!, 你们这么干这么干…” 激励技巧应变能力驾驭能力组织和协调能力的体现, 为有效完成目标, 需要调动所有成员积极性。首先要提升自己的语言组织和宣导能力，提升自己实操技能，敢于承担和付出， 取得大家认可。 培训能力定期对自己总结和分析，提升自己语言组织和表达能力，将自己知识和经验分享 学习能力自我反思，学习别人优点，更多的技能知识]]></content>
      <categories>
        <category>面试</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[缓存算法]]></title>
    <url>%2F2018%2F11%2F14%2F%E7%BC%93%E5%AD%98%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[LRU]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据库设计三范式]]></title>
    <url>%2F2018%2F11%2F13%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E4%B8%89%E8%8C%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[数据库设计三范式为了建立冗余小、结构合理的数据库，设计数据库必须遵循一定的原则。实际工最常用的三范式： 第一范式(确保每列保持原子性)第一范式是最基本的范式，表中的所有字段都是不可分割的原子值。 例如将“地址”这个属性重新拆分为省份、城市、详细地址等多个部分进行存储，这样在对地址中某一部分操作的时候将非常方便。这样设计才算满足了数据库的第一范式 第二范式(确保表中每列都和主键相关)第二范式在第一范式的基础上，确保表中每一列都与主键相关，而不能与主键的某一部分相关(主要针对联合主键)。 比如要设计一个订单信息表，因为订单中可能会有多种商品，所以要将订单编号和商品编号作为数据库表的联合主键，如下表所示: 订单编号 商品编号 商品名称 价格 客户 联系方式 001 1 车 10000 张三 88888888 002 2 帽子 5 李四 99999999 这个表中是以订单编号和商品编号作为联合主键。在该表中商品名称、单位、商品价格等信息不与该表的主键相关，而仅仅是与商品编号相关, 所以在这里违反了第二范式的设计原则。 如果把这个订单信息表进行拆分，把商品信息分离到另一个表中，把订单项目表也分离到另一个表中，就非常完美订单信息表 订单编号 客户 联系方式 001 张三 88888888 002 李四 99999999 订单项目表 订单编号 商品编号 数量 001 1 1 002 2 1 商品信息表 商品编号 商品名称 价格 1 车 10000 2 帽子 5 这样设计，在很大程度上减小了数据库的冗余。 第三范式(确保每列都是和主键直接相关，而不是间接相关)第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。 传递函数依赖：假设A、B和C是关系R的三个属性，如果A-〉B且B-〉C，则从这些函数依赖中，可以得出A-〉C，如上所述，依赖A-〉C是传递依赖。第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。 理解 1NF是对属性的原子性约束，要求属性具有原子性，不可再分解。通俗的理解是，字段还可以再分吗？如过不能，则是符合1NF的设计 2NF是对记录的惟一性约束，要求记录有惟一标识，即实体的惟一性。数据记录不重复冗余 3NF是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余 其他 鲍依斯-科得范式（BCNF）：满足 3NF，任何非主属性不能对主键子集依赖（消除 3NF 主属性对码的部分和传递函数依赖） 第四范式（4NF）：满足 3NF，属性之间不能有非平凡且非函数依赖的多值依赖（消除 3NF 非平凡且非函数依赖的多值依赖）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[开源协议区别]]></title>
    <url>%2F2018%2F11%2F12%2F%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[详细区别]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式锁实现]]></title>
    <url>%2F2018%2F11%2F10%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"></content>
      <categories>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分布式系统之CAP理论(1)]]></title>
    <url>%2F2018%2F11%2F06%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B9%8BCAP%E7%90%86%E8%AE%BA-1%2F</url>
    <content type="text"><![CDATA[CAP理论2000年7月，加州大学伯克利分校的Eric Brewer教授在ACM PODC会议上提出CAP猜想。2年后，麻省理工学院的Seth Gilbert和Nancy Lynch从理论上证明了CAP。之后，CAP理论正式成为分布式计算领域的公认定理。 CAP理论为：一个分布式系统最多只能同时满足一致性(Consistency)、可用性(Availability)和分区容错性(Partition tolerance)这三项中的两项。 Consistency一致性指“all nodes see the same data at the same time”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。 对于一致性，可以分为从客户端和服务端两个不同的视角。从客户端来看，一致性主要指的是多并发访问时更新过的数据如何获取的问题。从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致。 一致性是因为有并发读写才有的问题，因此在理解一致性的问题时，一定要注意结合考虑并发读写的场景。从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。 Availability可用性指“Reads and writes always succeed”，即服务一直可用，而且是正常响应时间 对于一个可用性的分布式系统，每一个非故障的节点必须对每一个请求作出响应。所以，一般我们在衡量一个系统的可用性的时候，都是通过停机时间来计算的。 Partition tolerance分区容错性指“the system continues to operate despite arbitrary message lossor failure of part of the system”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。 分区容错性和扩展性紧密相关。在分布式应用中，可能因为一些分布式的原因导致系统无法正常运转。好的分区容错性要求能够使应用虽然是一个分布式系统，而看上去却好像是在一个可以运转正常的整体。比如现在的分布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求，或者是机器之间有网络异常，将分布式系统分隔未独立的几个部分，各个部分还能维持分布式系统的运作，这样就具有好的分区容错性。 简单点说，就是在网络中断，消息丢失的情况下，系统如果还能正常工作，就是有比较好的分区容错性。 CAP理论中的CA和数据库事务中ACID的CA并完全是同一回事儿. 两者之中的A都是C都是一致性(Consistency).CAP中的A指的是可用性 (Availability),而ACID中的A指的是原子性(Atomicity),切勿混为一谈. CAP权衡CA without P分布式系统中几乎是不存在的。首先在分布式环境下，网络分区是一个自然的事实。因为分区是必然的，所以如果舍弃P，意味着要舍弃分布式系统。那也就没有必要再讨论CAP理论了。这也是为什么在前面的CAP证明中，我们以系统满足P为前提论述了无法同时满足C和A。 比如我们熟知的关系型数据库，如My Sql和Oracle就是保证了可用性和数据一致性，但是他并不是个分布式系统。一旦关系型数据库要考虑主备同步、集群部署等就必须要把P也考虑进来。 CP without A如果一个分布式系统不要求强的可用性，即容许系统停机或者长时间无响应的话，就可以在CAP三者中保障CP而舍弃A。 一个保证了CP而一个舍弃了A的分布式系统，一旦发生网络故障或者消息丢失等情况,就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。 设计成CP的系统其实也不少，其中最典型的就是很多分布式数据库，他们都是设计成CP的。在发生极端情况时，优先保证数据的强一致性，代价就是舍弃系统的可用性。如Redis、HBase等，还有分布式系统中常用的Zookeeper也是在CAP三者之中选择优先保证CP的。 无论是像Redis、HBase这种分布式存储系统，还是像Zookeeper这种分布式协调组件。数据的一致性是他们最最基本的要求。一个连数据一致性都保证不了的分布式存储要他有何用？ 在我的Zookeeper介绍（二）——Zookeeper概述一文中其实介绍过zk关于CAP的思考，这里再简单回顾一下： ZooKeeper是个CP（一致性+分区容错性）的，即任何时刻对ZooKeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性。但是它不能保证每次服务请求的可用性，也就是在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。ZooKeeper是分布式协调服务，它的职责是保证数据在其管辖下的所有服务之间保持 同步、一致。所以就不难理解为什么ZooKeeper被设计成CP而不是AP特性的了。 AP without C要高可用并允许分区，则需放弃一致性。一旦网络问题发生，节点之间可能会失去联系。为了保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。 这种舍弃强一致性而保证系统的分区容错性和可用性的场景和案例非常多。前面我们介绍可用性的时候说到过，很多系统在可用性方面会做很多事情来保证系统的全年可用性可以达到N个9，所以，对于很多业务系统来说，比如淘宝的购物，12306的买票。都是在可用性和一致性之间舍弃了一致性而选择可用性。 你在12306买票的时候肯定遇到过这种场景，当你购买的时候提示你是有票的(但是可能实际已经没票了)，你也正常的去输入验证码，下单了。但是过了一会系统提示你下单失败，余票不足。这其实就是先在可用性方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，会影响一些用户体验，但是也不至于造成用户流程的严重阻塞。 但是，我们说很多网站牺牲了一致性，选择了可用性，这其实也不准确的。就比如上面的买票的例子，其实舍弃的只是强一致性。退而求其次保证了最终一致性。也就是说，虽然下单的瞬间，关于车票的库存可能存在数据不一致的情况，但是过了一段时间，还是要保证最终一致性的。 对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9，即保证P和A，舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分布式系统之一致性算法Raft(6)]]></title>
    <url>%2F2018%2F11%2F06%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B9%8B%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95Raft-6%2F</url>
    <content type="text"><![CDATA[前言Raft 也是一个 易于理解一致性算法，和 Paxos 目标相同, 区别在于选举的 具体过程 不同。 什么是Raft协议Raft 协议组织的集群中有三类角色： Leader（领袖） Follower（群众） Candidate（候选人） 一个 Server 进程在某一时刻，只能是其中 一种类型，但这不是固定的。不同的时刻，它可能拥有不同的类型，一个 Server 进程的类型是如何改变的，后面会有解释。 就像一个民主社会，领袖由民众投票选出。刚开始没有 领袖，所有集群中的 参与者 都是 群众，那么首先开启一轮大选。在大选期间 所有群众 都能参与竞选，这时所有群众的角色就变成了 候选人，民主投票选出领袖后就开始了这届领袖的任期，然后选举结束，所有除 领袖 的 候选人 又变回 群众角色 服从领袖领导。 这里提到一个概念 「任期」，用术语 Term 表达。关于 Raft 协议的核心概念和术语就这么多，而且和现实民主制度非常匹配，所以很容易理解。 三类角色的变迁图如下： Leader选举过程在极简的思维下，一个最小的 Raft 民主集群需要 三个参与者（如下图：A、B、C），这样才可能投出多数票。 初始状态 ABC 都是 Follower，然后发起选举这时有 三种 可能的情形发生。下图中前二种都能选出 Leader，第三种则表明 本轮投票无效（Split Votes）。对于第三种，每方都投给了自己，结果没有任何一方获得多数票。之后 每个参与方 随机休息一阵（Election Timeout）重新发起投票直到一方获得多数票。这里的关键就是随机timeout，最先从 timeout 中恢复发起投票的一方，向还在 timeout 中的另外两方 请求投票，这时它就只能投给自己，导致很快达成一致。 选出 Leader 后，Leader 通过 定期 向所有 Follower 发送 心跳信息 维持其统治。若 Follower 一段时间未收到 Leader 的 心跳，则认为 Leader 可能已经挂了，然后再次发起 选举 过程。 Leader对一致性的影响Raft 协议 强依赖 Leader 节点的 可用性，以确保集群 数据的一致性。数据的流向 只能从 Leader 节点向Follower 节点转移。具体过程如下： 当 Client 向集群 Leader 节点 提交数据 后，Leader 节点 接收到的数据 处于 未提交状态（Uncommitted） 接着 Leader 节点会 并发地 向所有 Follower 节点 复制数据 并 等待接收响应 集群中至少 超过半数 的节点 已接收 到数据后， Leader 再向 Client 确认数据 已接收 一旦向 Client 发出数据接收 Ack 响应后，表明此时 数据状态 进入 已提交（Committed），Leader 节点再向 Follower 节点发通知告知该 数据状态已提交 在这个过程中，主节点 可能在 任意阶段 挂掉，看下 Raft 协议如何针对不同阶段保障 数据一致性 的。 情形1数据到达 Leader 节点前，这个阶段 Leader 挂掉不影响一致性，不用多说。 情形2数据到达 Leader 节点，但未复制到 Follower 节点。这个阶段 Leader 挂掉，数据属于 未提交状态，Client 不会收到 Ack 会认为 超时失败 可安全发起 重试。 Follower 节点上没有该数据，重新选主 后 Client 重试 重新提交 可成功。原来的 Leader 节点 恢复 后作为Follower 加入集群，重新从 当前任期 的新 Leader 处 同步数据，强制保持和 Leader 数据一致。 情形3情形4情形5情形6情形7验证结果综上穷举分析了 最小集群（3 节点）面临的所有情况，可以看出 Raft 协议都能很好的应对 一致性问题，并且很容易理解。 小结Paxos 算法是 Leslie Lamport 在 1990 年就公开发表在了自己的网站上，想想我们是什么时候才听说的？什么时候才有一个可用的实现？而 Raft 算法是 2013 年发表的，大家在参考 Raft开源实现库，可以看到有很多基于不同语言的 开源实现库，这就是 可理解性 的重要性。]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分布式系统之一致性算法Paxos(5)]]></title>
    <url>%2F2018%2F11%2F06%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B9%8B%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95Paxos-5%2F</url>
    <content type="text"><![CDATA[前言世界上只有一种一致性算法, 就是Paxos(帕克索斯), 出自一位 Google 大神之口。 Paxos解决了2PC，3PC中的各种硬伤, 在很多大长都有工程实践。比如阿里的 OceanBase 分布式数据库，底层就是使用的 Paxos 算法。再比如 Google 的 chubby 分布式锁 也是用的这个算法。可见该算法在分布式系统中的地位，甚至于Paxos 就是 分布式一致性 的代名词。 1. Paxos算法是什么Paxos 算法是 基于消息传递 且具有 高效容错特性 的一致性算法，目前公认的解决 分布式一致性问题 最有效 的算法之一。2. 解决了什么问题(产生背景)在常见的 分布式系统 中，总会发生 节点宕机 或 网络异常 (包括消息的 重复、丢失、延迟、乱序、网络分区)等情况。Paxos 算法主要就是解决如何在一个 发生如上故障 的分布式系统中，快速正确的在集群内 对某个值达成一致，并且保证 整个系统的一致性。 3. 算法详解角色 Proposer: Proposer 可以 提出提案 (Proposal)Acceptor: Acceptor 可以 接受提案。一旦接受提案，提案 里面的 value 值就被选定了Leaner: Acceptor 告诉 Learner 哪个提案被选定了，那么 Learner 就学习这个被选择的 value在具体的实现中，一个进程即可能是Proposer,也可能是Acceptor，也可能是Learner。 注意：提案的范围&gt;value.后面会讲到，[提案=编号+Value].也可表示为[M,V].以下描述中暂定: 提案=P，Value=V 问题描述Paxos 算法的核心是 一致性。所以将从一致性问题的描述来讲解该算法怎么解决实际问题。 一致性算法的前置条件 在被提出的 P 中，只有一个 V 被选中如果没有 P 被提出，就没有 V 被选中在 P 被选定后，进程都可以学习被选中的 P 不同角色通过发送消息进行通信 每个角色以任意的速度执行，可能因出错而停止，也可能会重启。一个 value 被选定后，所有的角色可能失败然后重启，除非那些失败后重启的角色能记录某些信息，否则等他们重启后无法确定被选定的值 消息在传递过程中可能出现 任意时长的延迟，可能会 重复，也可能 丢失，但是消息不会被 损坏 推导过程只有一个Acceptor 问题：如果这个 Acceptor 宕机，那么整个系统服务不可用 多个Acceptor 问题：如何在多 Proposer 和多 Acceptor 情况下，选定一个 value？ 讲解步骤分两阶段：约定 P1 和 约定 P2。 约定P1 P1 ：一个 Acceptor 必须接受一个它收到的第一个 P。 如果每个 Proposer 会产生不同的 P，那么多个 Proposer 必定产生多个 P，发给多个 Acceptor。根据 约定 P1，Acceptor 分别接受到 P，就会导致不同的 V 被选定，如下图所示：如上图所示，P1 会产生的问题: v1、v2、v3 都没有被选定，因为他们只有被一个 Acceptor 接受。对于上述问题，我们需要一个额外的约定: P1a : 一个提案 P 被选定，需要被半数以上 Acceptor 接受. 对于 P1a，其实就意味着 一个Acceptor必须接受不止一个提案。显然，这与 P1 相矛盾，所以需要重新设计提案。原来的设计是: [提案P = value]，现在重新设计 [提案P = 提案编号 + value]，可表示为 [M，V]。 新问题：多提案被选定，如何保证被选定的提案 P 具有相同的value? 约定P2 P2 : 如果提案 P[M0,V0] 被选定了，那么所有比 M0 编号更高的，且被选定的 P，其 value 的值也是 V0。 对于 P2 中的 “被选定”：一个提案要被选定，首先至少要被一个 Acceptor 批准。因此，可以理解 P2 为： P2a : 如果提案 P[M0,V0] 被选定了，那么所有比 M0 编号更高的，且 [被Acceptor批准] 的P，其 value值也是 V0。 只要满足 P2a，就能满足 P2。多提案被选择 的问题解决了，但是由于 网络不稳定 或者 宕机 的原因(不可避免)会产生新问题： 假设有 5 个 Acceptor。Proposer2 提出 [M1,V1]的提案，Acceptor2~5（半数以上）均接受了该提案，于是对于 Acceptor2~5 和 Proposer2 来讲，它们都认为 V1 被选定。Acceptor1 刚刚从 宕机状态 恢复过来（之前 Acceptor1 没有收到过任何提案），此时 Proposer1 向 Acceptor1 发送了 [M2,V2] 的提案（V2≠V1且M2&gt;M1）。对于 Acceptor1 来讲，这是它收到的 第一个提案。根据 P1（一个 Acceptor 必须接受它收到的 第一个提案），Acceptor1 必须接受该提案。同时 Acceptor1 认为 V2 被选定。 这就出现了两个问题： Acceptor1 认为 V2 被选定，Acceptor2~5 和Proposer2 认为 V1 被选定。出现了不一致。 V1 被选定了，但是 编号更高 的被 Acceptor1 接受的提案 [M2,V2] 的 value 为 V2，且 V2≠V1。这就跟 P2a（如果某个 value 为 v的提案被选定了，那么每个 编号更高 的被 Acceptor 接受的提案的 value必须也是 v）矛盾了 基于以上问题，所有就有了 P2b: P2b : 如果 P[M0,V0] 被选定后，任何 Proposer 产生的 P，其值也是 V0 对于 P2b 中的描述，怎样保证 任何Proposer产生的P，其值也是V0 ？只要满足 P2c 即可： P2c: 对于任意的 M、V，如果 [M,V] 被提出，那么存在一个半数以上的 Acceptor 组成的组合 S，满足以下两个条件中的任何一个： S 中没有一个接受过编号小于 M 的提案。 S 中的 Acceptor 接受过的最大编号的提案的 value 为 V。 算法流程Proposer提出提案(一). 学习阶段：Prepare请求Proposer 选择一个新的提案 P[MN,?] 向 Acceptor 集合 S（数目在半数以上）发送请求，要求 S 中的每一个 Acceptor 做出如下响应: 如果 Acceptor 没有接受过提案，则向 Proposer 保证 不再接受编号小于N的提案 如果 Acceptor 接受过请求，则向 Proposer 返回 已经接受过的编号小于N的编号最大的提案 (二). 接受阶段：Acceptor请求 如果 Proposer 收到 半数以上 的 Acceptor 响应，则 生成编号为 N，value 为 V 的提案[MN,V]，V 为所有响应中 编号最大 的提案的 value 如果 Proposer 收到的响应中 没有提案，那么 value 由 Proposer 自己生成，生成后将此提案发给 S，并期望 Acceptor 能接受此提案 Acceptor接受提案Acceptor 可以忽略任何请求（包括 Prepare 请求和 Accept 请求）而不用担心破坏 算法的安全性。什么时候 Acceptor 可以响应一个请求? P1b：一个 Acceptor 只要尚未响应过任何编号大于 N 的 Prepare 请求，那么就可以接受这个编号为 N 的提案。 如果 Acceptor 收到一个编号为 N 的 Prepare 请求，在此之前它已经 响应过 编号大于 N 的Prepare 请求。根据 P1b，该 Acceptor 不可能接受编号为 N 的提案。因此，该 Acceptor 可以忽略 编号为 N 的 Prepare 请求。当然，也可以回复一个 error，让 Proposer 尽早知道自己的提案 不会被接受。 因此，一个 Acceptor 只需记住: 已接受的编号最大的提案 已响应的请求的最大编号 4. Paxos算法描述5. Learner学习提案6. 如何保证Paxos算法的活性7. 小结Paxos 在 节点宕机恢复、消息无序或丢失、网络分化 的场景下能保证 数据的一致性。而 Paxos的描述侧重于 理论，在实际项目应用中，处理了 N 多实际细节后，可能已经变成了另外一种算法，这时候正确性已经无法得到理论的保证。 要证明分布式一致性算法的正确性通常比实现算法还困难。所以很多系统实际中使用的都是以 Paxos理论 为基础而 衍生 出来的变种和简化版。例如 Google 的 Chubby、MegaStore、Spanner 等系统，ZooKeeper 的 ZAB 协议，还有更加容易理解的 Raft 协议。]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分布式系统之3PC(4)]]></title>
    <url>%2F2018%2F11%2F06%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B9%8B3PC-4%2F</url>
    <content type="text"><![CDATA[前言三阶段提交对二阶段提交存在的问题进行了改进： 引入超时机制 - 同时在协调者和参与者中都引入超时机制。 在第一阶段和第二阶段中插入一个准备阶段，保证了在最后提交阶段之前各参与节点的状态是一致的。 3PC定义三阶段提交(Three-phase commit), 是二阶段提交的改进版本。所谓的三个阶段分别是：询问，然后再锁资源，最后真正提交。 第一阶段：CanCommit 第二阶段：PreCommit 第三阶段：Do Commit 3PC过程一、CanCommit协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。 事务询问 协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。 响应反馈 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态；否则反馈No。 二、PreCommit协调者在得到所有参与者的响应之后，会根据结果执行2种操作：执行事务预提交，或者中断事务。 执行事务预提交 发送预提交请求 协调者向所有参与者节点发出 preCommit 的请求，并进入 prepared 状态 事务预提交 参与者受到 preCommit 请求后，会执行事务操作，对应 2PC 准备阶段中的“执行事务”，也会 Undo 和 Redo 信息记录到事务日志中 各参与者响应反馈 如果参与者成功执行了事务，就反馈 ACK 响应，同时等待指令：提交（commit） 或终止（abort）。 中断事务 发送中断请求 协调者向所有参与者节点发出 abort 请求 中断事务 参与者如果收到 abort 请求或者超时了，都会中断事务 三、DoCommit该阶段进行真正的事务提交，分为执行提交，或中断事务。 执行提交 发送提交请求 协调者接收到各参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送 doCommit 请求。 事务提交 参与者接收到 doCommit 请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。 响应反馈 事务提交完之后，向协调者发送 ACK 响应 完成事务 协调者接收到所有参与者的 ACK 响应之后，完成事务 中断事务协调者没有接收到参与者发送的 ACK 响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。 发送中断请求 协调者向所有参与者发送 abort 请求。 事务回滚 参与者接收到 abort 请求之后，利用其在阶段二记录的 undo 信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。 反馈结果 参与者完成事务回滚之后，向协调者发送 ACK 消息。 中断事务 协调者接收到参与者反馈的 ACK 消息之后，完成事务的中断。 优缺点 优点相对于二阶段提交，三阶段提交主要解决的单点故障问题，并减少了阻塞的时间。因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行 commit。而不会一直持有事务资源并处于阻塞状态。 缺点三阶段提交也会导致数据一致性问题。由于网络原因，协调者发送的 abort 响应没有及时被参与者接收到，那么参与者在等待超时之后执行了 commit 操作。这样就和其他接到 abort 命令并执行回滚的参与者之间存在数据不一致的情况]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分布式系统之2PC(3)]]></title>
    <url>%2F2018%2F11%2F06%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B9%8B2PC-3%2F</url>
    <content type="text"><![CDATA[前言由于BASE理论需要在一致性和可用性方面做出权衡，因此涌现了很多关于一致性的算法和协议。其中比较著名的有二阶提交协议（2 Phase Commitment Protocol），三阶提交协议（3 PhaseCommitment Protocol）和Paxos算法。 本文要介绍的2PC协议，分为两个阶段提交一个事务。并通过协调者和各个参与者的配合，实现分布式一致性。 角色 XA概念 作用 协调者 事务管理器 协调各个参与者,对分布式事务进行提交或回滚 参与者 资源管理器 分布式集群中的节点 分布式事务分布式事务是指会涉及到操作多个数据库的事务。目的是为了保证分布式系统中的数据一致性关键： 需要记录事务在任何节点所做的所有动作 事务进行的所有操作要么全部提交，要么全部回滚 XA规范XA规范是由 X/Open组织（即现在的 Open Group ）定义的分布式事务处理模型。 X/Open DTP模型（ 1994 ）包括： 应用程序（ AP ） 事务管理器（ TM ）：交易中间件等 资源管理器（ RM ）：关系型数据库等 通信资源管理器（ CRM ）：消息中间件等 XA规范定义了交易中间件与数据库之间的接口规范（即接口函数），交易中间件用它来通知数据库事务的开始、结束以及提交、回滚等。而XA接口函数由数据库厂商提供 二阶提交协议和三阶提交协议就是基于XA规范提出的其中，二阶段提交就是实现XA分布式事务的关键。 XA规范的流程，大致如图所示： 2PC定义每个参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报，决定各参与者是否要提交操作还是中止操作。 准备阶段准备阶段分为三个步骤： 事务询问协调者向所有的参与者询问，是否准备好了执行事务，并开始等待各参与者的响应。 执行事务各参与者节点执行事务操作。如果本地事务成功，将Undo和Redo信息记入事务日志中，但不提交；否则，直接返回失败，退出执行。 各参与者向协调者反馈事务询问响应如果参与者成功执行了事务操作，那么就反馈给协调者 Yes响应，表示事务可以执行提交；如果参与者没有成功执行事务，就返回No给协调者，表示事务不可以执行提交。 提交阶段根据准备阶段的投票结果执行2种操作:提交事务或中断事务 提交事务过程 发送提交请求协调者向所有参与者发出commit请求。 事务提交参与者收到commit请求后，会正式执行事务提交操作，并在完成提交之后，释放整个事务执行期间占用的事务资源。 反馈事务提交结果参与者在完成事务提交之后，向协调者发送Ack信息。 事务提交确认协调者接收到所有参与者反馈的Ack信息后，完成事务。 中断事务过程 发送回滚请求协调者向所有参与者发出Rollback请求。 反馈事务回滚结果参与者在完成事务回滚之后，想协调者发送Ack信息。 事务回滚参与者接收到Rollback请求后，会利用其在提交阶段种记录的Undo信息，来执行事务回滚操作。在完成回滚之后，释放在整个事务执行期间占用的资源。 事务中断确认协调者接收到所有参与者反馈的Ack信息后，完成事务中断。 优缺点 优点：原理简单，实现方便。 缺点：同步阻塞，单点问题，数据不一致，容错性不好。 同步阻塞所有的节点都在等待其他节点的响应，无法进行其他操作。这种同步阻塞极大的限制了分布式系统的性能。(mapreduce里面是顺序执行) 单点问题协调者是个单点, 如果协调者在提交阶段出现问题，那么整个流程将无法运转 数据不一致协调者向所有的参与者发送commit请求之后，发生了局部网络异常，或者是协调者在尚未发送完所有 commit请求之前自身发生了崩溃，导致最终只有部分参与者收到了commit请求。 容错性不好如果在二阶段提交的提交询问阶段中，参与者出现故障，导致协调者始终无法获取到所有参与者的确认信息，这时协调者只能依靠其自身的超时机制，判断是否需要中断事务。显然，这种策略过于保守。换句话说，二阶段提交协议没有设计较为完善的容错机制，任意一个节点是失败都会导致整个事务的失败。]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分布式系统之BASE理论(2)]]></title>
    <url>%2F2018%2F11%2F06%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B9%8BBASE%E7%90%86%E8%AE%BA-2%2F</url>
    <content type="text"><![CDATA[前言BASE理论是由eBay架构师提出的. BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网分布式系统实践的总结, 是基于CAP定律逐步演化而来. 其核心思想是即使无法做到强一致性, 但每个应用都可以根据自身业务特点，才用适当的方式来使系统达到最终一致性 BASE理论简介BASE理论是Basically Available(基本可用), Soft State(软状态), Eventually Consistent(最终一致性)三个短语的缩写 其核心思想是： 既是无法做到强一致性, 但每个应用可以根据自身的业务特点, 采用适当的方式来是系统达到最终一致性 BASE理论的内容基本可用当系统出现了不可预知故障, 但还是能用, 就是基本可用。。。 响应时间的止损失：正常情况下的搜索引擎0.5秒即返回给用户结果，而基本可用的搜索引擎可以在2秒作用返回结果 功能上的损失：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单。但是到了大促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。 软状态相对于原子性而言，要求多个节点的数据副本都是一致的，这是一种“硬状态”。 软状态指的是：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。 最终一致性在一定期限后，应当保证所有副本数据一致性，从而达到数据的最终一致性。时间期限取决于网络延迟、系统负载、数据复制方案设计等 在实际工程实践中，最终一致性分为5种： 因果一致性（Causal consistency）如果节点A在更新了数据后通知了B，那么B对该数据的访问都是基于A更新修改后的值。与此同时,和节点A无因果关系的节点C的数据访问没有这样的限制 读己之所写（Read your writes）节点A更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性 会话一致性（Session consistency）对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现 “读己之所写”的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。 单调读一致性（Monotonic read consistency）如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。 单调写一致性（Monotonic write consistency）一个系统要能够保证来自同一个节点的写操作被顺序的执行。 在实际的实践中，这5种系统往往会结合使用，以构建一个具有最终一致性的分布式系统。 实际上，不只是分布式系统使用最终一致性，关系型数据库在某个功能上，也是使用最终一致性的。比如备份，数据库的复制过程是需要时间的，这个复制过程中，业务读取到的值就是旧的。当然，最终还是达成了数据一致性。这也算是一个最终一致性的经典案例。 小结总体来说BASE理论面向的是大型高可用、可扩展的分布式系统。与传统ACID特性相反，不同于ACID的强一致性模型，BASE提出通过牺牲强一致性来获得可用性，并允许数据段时间内的不一致，但是最终达到一致状态。同时，在实际分布式场景中，不同业务对数据的一致性要求不一样。因此在设计中，ACID和BASE理论往往又会结合使用。]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[算法图解笔记]]></title>
    <url>%2F2018%2F11%2F05%2F%E7%AE%97%E6%B3%95%E5%9B%BE%E8%A7%A3%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据结构笔记]]></title>
    <url>%2F2018%2F11%2F05%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第一章 绪论冒泡排序 遍历A[0, n] 依次比较相邻两个数, 若A[i-1]小于A[i], 则交换, 并设置循环遍历标记; 一次循环必然可确定一个最大值, n递减; 1234567891011121314151617void bubble_sort(int A[], n)&#123; bool bSort = false; while(bSort) &#123; bSort = false; for(int i=1; i&lt;n; i++) &#123; if(A[i-1]&gt;A[i]) &#123; swap(A[i-1], A[i]); bSort = true; &#125; &#125; n--; &#125;&#125; 复杂度度量大O记号性质a) 对于任意常数c&gt;0, 有$ O(f(n)) = O(c*f(n)) $b) 对于任意常数a&gt;b&gt;0, $ 有O(n^a + n^b) = O(n^a) $冒泡时间复杂度: $ T(n)=O(2(n-1)^2) = O(2n^2 + 4n + 2) = O(2n^2) = O(n^2) $ $ \Omega $ 标记为最乐观的下限复杂度, $ \Theta $ 上限复杂度 复杂度分析常数：$ T(n) = O(3) + O(2) + O(1) = O(7) = O(1) $对数：$ O(\log_2 n) = O(\log n) $指数：$ O(a^n) $ 1234567891011// 统计整数n二进制展开中数位1的个数int countOnes(unsigned int n)&#123; int num = 0; while(n&gt;0) &#123; num += (1&amp;n); n &gt;&gt; 1; &#125; return num;&#125; 递归线性递归二分递归多分支递归ADT第二章 向量从数组到向量]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[失败是成功他妈]]></title>
    <url>%2F2018%2F11%2F01%2F%E5%A4%B1%E8%B4%A5%E6%98%AF%E6%88%90%E5%8A%9F%E4%BB%96%E5%A6%88%2F</url>
    <content type="text"><![CDATA[必须刷一遍思路清奇小土刀 大海捞针找到的c++面试徐刘根的JAVA面试大杂烩Google的面试Java后端知识体系总结系统设计入门x86-64体系下一个奇怪问题的定位2018/2019/校招/春招/秋招/自然语言处理(NLP)/深度学习(Deep Learning)/机器学习(Machine Learning)/C/C++/Python/面试笔记]]></content>
      <categories>
        <category>面试</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[网络编程实践]]></title>
    <url>%2F2018%2F11%2F01%2F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[参考文章select1234567891011121314#include &lt;sys/select.h&gt;int select(int fd, fd_set* read, fd_set* write, fd_set* excp, struct timeval* tm);// 返回值：就绪描述符的数目，超时返回0，出错返回-1FD_ZERO(fd_set* fds);FD_SET(int fd, fd_set* fds);FD_CLR(int fd, fd_set* fds);FD_ISSET(int fd, fd_set* fds);#include &lt;sys/time.h&gt;struct timeval&#123;__time_t tv_sec; /* Seconds. */__suseconds_t tv_usec; /* Microseconds. */&#125;; 123456789101112131415while(1)&#123; fd_set fds; FD_ZERO(&amp;fds); FD_SET(sock, &amp;fds); int ret = select(fd+1, &amp;fds, 0, 0, NULL); /*NULL一直阻塞*/ if(FD_ISSET(sock, &amp;fds)) &#123; //read &#125;&#125;// 套接字的阻塞非阻塞不影响select ， 只会影响read/write. poll123456789101112131415161718#include &lt;poll.h&gt;int poll(struct pollfd fds[], unsigned int nfds, int timeout);param: fds 数组 nfds 描述符个数，无限制 timeout 阻塞时间，单位msreturn: 返回值 &gt;0 实际发生事件描述符总数 , ==0 超时, -1 失败 设置errno struct pollfd&#123; int fd; // 文件描述符 short events; // 等待事件 short revevents; // 实际发生事件&#125;;POLLIN | POLLPRI 读, POLLOUT | POLLWRBAND 写 123456789101112131415161718192021struct pollfd fds[OPEN_MAX];fds[0].events = POLLIN | POLLPRI;for(;;)&#123; switch(poll(&amp;fds, 1, timeout)) &#123; case 0: printf(&quot;timeout \n&quot;); case -1: printf(&quot;poll error \n&quot;); default: &#123; printf(&quot;some events \n&quot;); if(fds[0].revevents &amp; POLLIN) &#123; // accept and put into fds &#125; &#125; break; &#125;&#125; epoll1234567891011121314151617#include &lt;sys/epoll.h&gt;int epoll_create(int size); // 监听数量int epoll_ctl(int epfd, int op, int fd, struct epoll_event* event);int epoll_wait(int epfd, struct epoll_event* events, int maxevents, int timeout);struct epoll_event&#123; __uint32_t events; epoll_data_t data;&#125;EPOLLIN/EPOLLOUT/EPOLLPRI/EPOLLERR/EPOLLHUP/EPOLLLET/EPOLLONESHOT工作模式： LT:应用程序可以不处理，下次还会再响应。 ET:需要立即处理，下次不会响应，默认ET，只响应一次。 必须使用非阻塞套接口，避免饿死其他套接口。 1234567891011121314151617181920212223242526272829void do_epool()&#123; int epollfd; struct epoll_event events[10]; epollfd = epoll_create(1024); events[0].events = EPOLLIN; events[0].data.fd = fd; epoll_ctl(epollfd, EPOLL_CTL_ADD, fd, &amp;(events[0])); for(;;) &#123; struct epoll_event eventArr[100]; // epoll_wait成功之后，储存所有的读写事件 num = epoll_wait(epollfd, eventArr, 1024, -1); for(int = 0; i&lt;num; ++i) &#123; if(eventArr[i].data.fd == lintenfd &amp;&amp;eventArr[i].events &amp; EPOLLIN) // accept else if(eventArr[i].events &amp; EPOLLIN) // 可读，有数据到来 // read else if(eventArr[i].events &amp; EPOLLOUT) // 可写，缓冲区从满==&gt;未满 // write else if(&amp; EPOLLHUP) //RST响应,在epoll上会响应为EPOLLHUP // do something &#125; &#125; close(epollfd); // &#125; 总结select的几大缺点： 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大select支持的文件描述符数量太小了，默认是1024 差异select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。 select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。 这也能节省不少的开销。阻塞/非阻塞设置12345#include &lt;fcntl.h&gt;fcntl(FD, F_SETFL, O_NONBLOCK);iFlag = 0;if( ioctl( nSock, FIONBIO, &amp;iFlag) &lt; 0) read123456789101112131415161718192021222324252627int readN(char* pBuf, int nByte)&#123; int nLeft = nByte; int nRead = 0; while(nLeft &gt; 0) &#123; nRead = read( m_nSock, pBuf, nLeft); if(nRead &lt; 0) // &#123; if(errno == EINTR) // 收到信号并从信号处理函数返回时，慢系统调用会返回并设 continue; if(errno == EAGAIN) // 示当前暂时没有数据可读，应该稍后读取 continue; &#125; else if(nRead == 0) //接收到对端发送的FIN，表示对端的写端关闭。 &#123; break; &#125; else //读取数据的长度 &#123; nLeft -= nRead; pBuf += nRead; &#125; &#125; reutrn nByte - nLeft;&#125; write12345678910111213141516171819202122232425int writeN(char* pBuf, int nByte)&#123; int nLeft = nByte; int nWrite = 0; while(nLeft &gt; 0) &#123; nWrite = write(m_nSock, pBuf, nLeft); if(nWrite &lt;=0) &#123; if(errno == EINTR) continue; if(errno == EAGAIN) // 水平模式下,如果返回EAGAIN，把socket加入epoll， // 在epoll的驱动下写数据，全部数据发送完毕后，再移出epoll //do something return nWrite; &#125; nLeft -= nWrite; pBuf += nWrite;s &#125; reutrn nByte - nLeft;&#125;//如果向已经关闭的对端调用write, 系统会向程序发送SIGPIPE信号 ET模式下，EPOLLOUT触发条件有：1.缓冲区满–&gt;缓冲区非满；2.同时监听EPOLLOUT和EPOLLIN事件 时，当有IN 事件发生，都会顺带一个OUT事件； 3.一个客户端connect过来，accept成功后会触发一次OUT事件。踩过的坑errnoerrno是线程安全的, 在一个线程中设置它, 不会影响别的线程对它的使用如果你的程序对它有依赖, 需要开发人员在接口错误处理中手工设置 粘包客户端没有收完整, 导致收下一个包core]]></content>
      <categories>
        <category>网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[网络模型概念]]></title>
    <url>%2F2018%2F11%2F01%2F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[在Linux中，对于一次读取IO的操作, 包含两个阶段 1 Waiting for the data to be ready(等待数据到达内核缓冲区)2 Copying the data from the kernel to the process(从内核缓冲区拷贝数据到程序缓冲区) 对于同步、异步IO, Stevens给的定义 A synchronous I/O operation causes the requesting process to beblocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked; 根据IO操作和进程的关系，分为五种模型 阻塞IOIO操作的两个阶段都阻塞, 用户进程一直等待系统调用返回 非阻塞IO前三次调用立即返回, 第四次调用内核数据已经准备好, 但是从内核缓冲区拷贝数据到程序缓冲区时用户进程会等待系统调用返回 IO复用select等待数据到达内核缓冲区(或超时), recvfrom从内核缓冲区拷贝数据到程序缓冲区, 两个过程用户进程分别会阻塞等待调用返回 信号驱动设置socket为一个信号驱动IO, 内核数据准备好后通知用户进程.用户进程调用recform, 等待从内核缓冲区拷贝数据到程序缓冲区, 这个过程用户进程阻塞等待 异步IO用户进程调用aio_read后, 可以继续执行, 等待IO操作两个阶段完成收到信号通知, 读取数据 总结前四种都是同步型IO操作, 只有异步IO才是异步型IO操作。]]></content>
      <categories>
        <category>网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一致性hash算法]]></title>
    <url>%2F2018%2F10%2F30%2F%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[常规思路： 1.是什么2.解决了什么问题3.是怎么实现的 hash问题数据库中分库分表规则，按照hash取值、取模、按类别、按某一个字段。例如redis集群使用hash的方式，对图片缓存, 对服务器的数量进行取模hash(a.png)%4 = 2 当我们增加或减少一台服务器时，hash(a.png)%5=? hash(a.png)%3=？redis缓存的图片就找不到了，都会想后端数据库直请求，引发缓存雪崩 一致性hash一致性Hash算法是对2^32取模, 整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形）整个哈希环如下: 整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1，也就是说0点左侧的第一个点代表2^32-1，0和2^32-1在零点中方向重合，我们把这个由2^32个点组成的圆环称为Hash环。 下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用IP地址哈希后在环空间的位置如下： 下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用IP地址哈希后在环空间的位置如下： 将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器！ 例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下： 根据一致性Hash算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。 一致性Hash算法的容错性和可扩展性一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 Hash环的数据倾斜问题一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器，其环分布如下： 此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。 同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，使很少的服务节点也能做到相对均匀的数据分布]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[准备好吹牛B]]></title>
    <url>%2F2018%2F10%2F29%2F%E5%87%86%E5%A4%87%E5%A5%BD%E5%90%B9%E7%89%9BB%2F</url>
    <content type="text"><![CDATA[BOSS系统介绍 整体功能架构计费功能架构计费技术架构计费对外接口设计部署方案(接入/应用/数据) (集群、负载均衡、分布式、数据一致性的区别与关系)高可用及容灾设计和测试(mdb) 遇到过的问题 网络粘包, errno死锁binlog乱序, 索引优化内存泄漏(lua,new/del)性能优化, 主机问题(linux时钟源, ssd调度方式cfq/deadline, ck和binglog文件rename, 自旋锁占CPU过高, 存储变为只读) 最得意的事]]></content>
      <categories>
        <category>面试</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[TCP协议相关概念]]></title>
    <url>%2F2018%2F10%2F29%2FTCP%E5%8D%8F%E8%AE%AE%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[1. TCP协议头部格式 DNS在应用层, TCP/UDP/PORT在传输层, IP在网络层, ARP在数据链路层去掉没有协议的表示层和会话层，就是TCP/IP五层网络模型OSI是Open System Interconnect的缩写，意为开放式系统互联 为什么需要2MSL？ Maximum Segment Lifetime 报文最大生存时间, 保证最后发送的ACK报文对端可以收到, 不然对端会重发FIN. 所以TIME_WAIT用来重发可能丢失的ACK 2. 三次握手四次分手 为什么需要三次握手？ 为了防止已经失效的连接请求报文段突然又传到服务端，因而产生错误比如A发送sync给B, 在网络延迟N时间后B才收到, B回复ack, 此时A可能已经关闭,B浪费了这个链接的资源 为什么需要四次分手？ 为了确保数据能够完成传输(确保对端收完数据) 3. TCP状态转换 4. TCP如何保证可靠传输三次握手, seq+ack, 超时重传, 流量控制, 拥塞控制 超时重传流量控制拥塞控制5. TCP粘包TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包, 从接收缓冲区看,后一包数据的头紧接着前一包数据的尾 产生原因 发送方 TCP默认会使用Nagle算法:1 只有上一个分组得到确认，才会发送下一个分组2 收集多个小分组，在一个确认到来时一起发送接受方 没有立即处理, TCP将收到的分组保存至接收缓存里, 缓冲区会存在多个包 解决办法 发送发关闭Nagle算法, TCP_NODELAY选项接受方 TCP协议没有处理机制, 通过应用层来处理应用层 定义消息包头(len+type)和包体(data), 收包时循环处理 6. TCP的四种定时器 重传计时器：Retransmission Timer坚持计时器：Persistent Timer保活计时器：Keeplive Timer时间等待计时器：Timer_Wait Timer 7. TIME_WAIT太多压测工具主动关闭链接，产生TIME_WAIT将近3W，导致后续链接失败 产生原因TIME_WAIT停留2MSL(max segment lifetime)时间 解决办法1234567891011121314151617181920#统计TCP套接字状态netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&apos;#表示开启SYN cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭net.ipv4.tcp_syncookies = 1#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；net.ipv4.tcp_tw_reuse = 1#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭net.ipv4.tcp_tw_recycle = 1#修改系統默认的 TIMEOUT 时间net.ipv4.tcp_fin_timeout = 30#查看系统本地可用端口极限值cat /proc/sys/net/ipv4/ip_local_port_range51_zjdev[/data01/zjgrp/zjdev]%cat /proc/sys/net/ipv4/ip_local_port_range32768 61000本地能向外连接61000-32768=28232个连接 8. TCP队列在Linux内核2.2之后，分离为两个backlog来分别限制半连接(SYN_RCVD状态)队列大小和全连接(ESTABLISHED状态)队列大小。 半连接状态为：服务器处于Listen状态时收到客户端SYN报文时放入半连接队列中，即SYN queue(服务器端口状态为：SYN_RCVD) 全连接状态为：TCP的连接状态从服务器（SYN+ACK）响应客户端后，到客户端的ACK报文到达服务器之前，则一直保留在半连接状态中；当服务器接收到客户端的ACK报文后，该条目将从半连接队列搬到全连接队列尾部，即 accept queue (服务器端口状态为：ESTABLISHED) 1234567891011121314151617181920212223242526# SYN queue 队列长度51_zjdev[/data01/zjgrp/zjdev]%cat /proc/sys/net/ipv4/tcp_max_syn_backlog2048# Accept queue 队列长度51_zjdev[/data01/zjgrp/zjdev]%cat /proc/sys/net/core/somaxconn128/*最终取min(128, 使用listen函数时传入的参数)。在Linux内核2.4.25之前，是写死在代码常量 SOMAXCONN ，在Linux内核2.4.25之后，在配置文件 /proc/sys/net/core/somaxconn 中直接修改， 或者在/etc/sysctl.conf 中配置 net.core.somaxconn = 128*/# 查看SYN queue 溢出[root@localhost ~]# netstat -s | grep LISTEN102324 SYNs to LISTEN sockets dropped# 查看Accept queue 溢出[root@localhost ~]# netstat -s | grep TCPBacklogDropTCPBacklogDrop: 2334# 查看Accept queue[root@zhangbb ~]# ss -lntState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 50 *:3306 *:* /*在LISTEN状态，其中 Send-Q 即为Accept queue的最大值，Recv-Q 则表示Accept queue中等待被服务器accept()*/]]></content>
      <categories>
        <category>网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[c++类型转换]]></title>
    <url>%2F2018%2F10%2F28%2Fc-%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[四种类型转换 const_cast 修改类型的const或volatile属性 static_cast 通常用于转换数值类型, 进行非多态的类型转换, 编译时检查 dynamic_cast 基类转换成子类, 基类必须要有虚函数 reinterpret_cast 比较底层的转换, 在非相关的类型之间转换; 操作结果只是简单的从一个指针到别的指针的值的二进制拷贝;在类型之间指向的内容不做任何类型的检查和转换 语法 xxx_cast (expression)]]></content>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c++智能指针]]></title>
    <url>%2F2018%2F10%2F28%2Fc-%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%2F</url>
    <content type="text"><![CDATA[智能指针 (头文件memory) auto_ptr c++11已摒弃, 所有权控制不够严格, 没有避免潜在的内存崩溃问题 shared_ptr 采用引用计数, 将一个原始指针分配给多个所有者; 大小为两个指针,一个用于对象，另一个用于包含引用计数的共享控制块(strong ref/weak ref) weak_ptr 提供对一个或多个shared_ptr实例拥有的对象的访问, 但不参与引用计数; 用于观察某个对象但不需要其保持活动状态 unique_ptr 只允许基础指针的一个所有者, 可移动, 但不可复制; 大小等同于一个指针且支持 rvalue 引用 auto_ptr废弃原因： 当把一个auto_ptr赋给另外一个auto_ptr时, 原指针变为野指针, 不安全 1234567891011void Fun(auto_ptr&lt;Test&gt; p1 )&#123; cout&lt;&lt;p1-&gt;m_a&lt;&lt;endl;&#125;void main( )&#123; std::auto_ptr&lt;Test&gt; p( new Test(5) ); Fun(p); cout&lt;&lt;p-&gt;m_a&lt;&lt;endl;&#125; auto_ptr不能指向一组对象, 不能和操作符new[]一起用, 会产生一个运行时错误 1234void main( )&#123; std::auto_ptr&lt;Test&gt; p(new Test[5]);&#125; auto_ptr不能和标准容器（vector,list,map….)一起使用 shared_ptr使用方式 为什么要尽量使用 make_shared为了节省一次内存分配, 原来 shared_ptr x(new Foo); 需要为 Foo 和 ref_count各分配一次内存, 现在用 make_shared()的话, 可以一次分配一块足够大的内存, 供 Foo和 ref_count 对象容身, 数据结构是： explicit构造函数, 不允许隐式转换 123456shared_ptr&lt;double&gt; pd; double *p_reg = new double;pd = p_reg; // not allowed (implicit conversion)pd = shared_ptr&lt;double&gt;(p_reg); // allowed (explicit conversion)shared_ptr&lt;double&gt; pshared = p_reg; // not allowed (implicit conversion)shared_ptr&lt;double&gt; pshared(p_reg); // allowed (explicit conversion) 方法 get(): 获取shared_ptr绑定的资源. reset(): 释放关联内存块的所有权，如果是最后一个指向该资源的shared_ptr,就释放这块内存 unique: 判断是否是唯一指向当前内存的shared_ptr operator bool : 判断当前的shared_ptr是否指向一个内存块，可以用if 表达式判断 存在问题 多个shared_ptrs对象用一个普通指针构造, 析构时core 123456void main( )&#123; int* p = new int; shared_ptr&lt;int&gt; sptr1( p); shared_ptr&lt;int&gt; sptr2( p );&#125; 用指针去创建shared_ptr, 不小心删除指针, 析构时core 循环引用, 资源都不会正常释放 12345678910void main( )&#123; shared_ptr&lt;B&gt; sptrB( new B ); shared_ptr&lt;A&gt; sptrA( new A ); // sptrB-&gt;m_sptrA shared_ptr sptrB-&gt;m_sptrA = sptrA; sptrA-&gt;m_sptrB = sptrB;&#125;4. 读线程不安全, 写线程不安全 weak_ptr使用方式 方法 调用lock()可以得到shared_ptr或者直接将weak_ptr转型为shared_ptr 调用use_count()去获取引用计数，该方法只返回强引用计数，并不返回弱引用计数 调用expired()方法。比调用use_count()方法速度更快 解决循环引用内存不会释放问题123456789void main( )&#123; shared_ptr&lt;B&gt; sptrB( new B ); shared_ptr&lt;A&gt; sptrA( new A ); // sptrB-&gt;m_sptrA weak_ptr sptrB-&gt;m_sptrA = sptrA; sptrA-&gt;m_sptrB = sptrB; sptrA-&gt;PrintSpB( ); &#125; unique_ptr优点 将一个unique_ptr赋值给另一个时, 如果源 unique_ptr是个临时右值, 编译器允许这么做 1234567unique_ptr&lt;string&gt; demo(const char * s)&#123; unique_ptr&lt;string&gt; temp (new string (s))； return temp；&#125;unique_ptr&lt;string&gt; ps;ps = demo(&apos;Uniquely special&quot;)； 无法赋值, 可以移动; 或者release释放后reset转移 12unique_ptr&lt;Foo&gt; ptr = make_unique&lt;Foo&gt;();Foo* p = ptr.release();]]></content>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gstack]]></title>
    <url>%2F2018%2F10%2F25%2Fgstack%2F</url>
    <content type="text"><![CDATA[123456#!bin/shwhile( true )do gstack $1&gt;&gt;gstack_$1.txtsleep 1done]]></content>
      <categories>
        <category>gdb</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Posix线程编程指南]]></title>
    <url>%2F2018%2F10%2F24%2FPosix%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[摘自 IBM developerWorks 图书频道 Posix线程编程指南线程创建与取消 线程私有数据线程同步线程终止杂项 通用线程：POSIX 线程详解一种支持内存共享的简捷工具称作互斥对象的小玩意使用条件变量提高效率 线程池的介绍及简单实现c++ 内存池]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux进程间通信]]></title>
    <url>%2F2018%2F10%2F24%2FLinux%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[摘自 IBM developerworks 郑彦兴 深刻理解Linux进程间通信(IPC) Linux环境进程间通信（一）Linux环境进程间通信（二）信号（上）Linux环境进程间通信（二）信号（下）Linux环境进程间通信（三）消息队列Linux环境进程间通信（四）信号灯Linux环境进程间通信（五）共享内存（上）Linux环境进程间通信（五）共享内存（下）Linux 环境进程间通信（六）套接口]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[zk原理和实践]]></title>
    <url>%2F2018%2F10%2F24%2Fzk%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[透彻的学习笔记ZooKeeper学习第一期—Zookeeper简单介绍ZooKeeper学习第二期–ZooKeeper安装配置ZooKeeper学习第三期—Zookeeper命令操作ZooKeeper学习第四期—构建ZooKeeper应用ZooKeeper学习第五期–ZooKeeper管理分布式环境中的数据ZooKeeper学习第六期—ZooKeeper机制架构ZooKeeper学习第七期–ZooKeeper一致性原理ZooKeeper学习第八期——ZooKeeper伸缩性实践]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2F2018%2F10%2F24%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"></content>
      <categories>
        <category>c++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[性能之巅 笔记]]></title>
    <url>%2F2018%2F10%2F24%2F%E6%80%A7%E8%83%BD%E4%B9%8B%E5%B7%85-%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第一章 绪论系统性能上对整个系统的研究，包括了所有硬件组件和整个软件栈。所有数据路径上和软硬件上发生的事情都包括在内，因为这些可能都影响性能。 性能领域包括以下事情： 1. 设置性能目标和建立性能模型 2. 基于软件或硬件原型进行性能特征归纳 3. 对开发的代码进行性能测试(软件整合之前) 4. 执行软件的非回归性测试(软件发布前或发布后) 5. 针对软件发布的基准测试 6. 目标环境中的概念验证测试 7. 生产环境的部署的配置优化 8. 监控生产环境中运行的软件 9. 特定问题的性能分析 术语容量规划是指一系列事前行动。在计划阶段，通过研究开发软件的资源占用情况，来得知原有设计在多大程度上能满足目标需求。在部署后，这样的问题在出现之前就能被预测。 性能分析必须量化问题的重要程度， 有一个指标非常合适，延时。 动态跟踪技术把所有的软件变得可以监控，而且能用在真实的生产环境中。这项技术利用内存中的CPU指令并在这些指令上动态构建检测数据。这样能从任何运行的软件中获得定制化的性能统计数据，从而提供了远超系统的自带的统计所能给予的观测性。 DTrace对用户态和内核态的软件都提供了静态跟踪和动态跟踪，并且数据是实时产生的。 第二章 方法术语：IOPS：每秒输入/输出的操作次数，是数据传输的一个度量方法。对于磁盘，就是每秒读和写的次数。吞吐量：数据传输或操作的速度响应时间：一次操作完成的时间延时: 操作里用来等待服务的时间使用率：对于服务所请求的资源，描述在给定的时间区间内资源的繁忙程度饱和度: 某一资源无法满足服务的排队工作量/瓶颈/工作负载/缓存 模型：第三章 操作系统了解操作系统和内核对于系统性能分析是至关重要的。会经常需要针对系统行为的开发和测试，如系统调用是如何执行的、CPU是如何调度线程的、有限大小的内存是如何影响性能的、或者文件系统是如何处理I/O的。 基本概念介绍，最好结合《深入理解计算机系统》： 内核：内核的执行/时钟/内核态栈：用户栈和内核栈; 用函数和寄存器的方式记录了线程的执行历史中断和中断线程进程：进程的创建、进程的生命周期、进程环境系统调用虚拟内存内存管理调度器文件系统：VFS、I/O栈缓存（括号内为例子）：应用程序缓存、服务器缓存(apache缓存)、缓存服务器(redis)、数据库缓存(mysql缓冲区高速缓存)、 目录缓存(DNLC)、文件元数据缓存(inode 缓存)、 操作系统缓存区高速缓存(segvn)、文件系统主缓存(ZFS ARC) 文件系统次缓存(ZFS L2ARC)、设备缓存(ZFS vdev)、 块缓存(缓冲区高速缓存)、磁盘控制器缓存(RAID卡缓存) 存储阵列缓存、磁盘内置缓存网络设备驱动多处理器：CPU交叉调用抢占资源管理观测性 第四章 观测工具工具可以按照系统级别和进程级别来分类，多数工具要么基于计数器要么基于跟踪。 系统级 | vmstat/iostat| mpstat/sar | dtrace/tcpdump |计数器——————-跟踪 pmap | ps | gdb/strace top | 进程级 计数器： 内核维护了各种统计数据，称为计数器，用于对事件的计数。通常计数器实现为无符号整形，发生事件时递增。 系统级别的计数器： vmstat: 虚拟内存和物理内存的统计 mpstat: 每个CPU的使用情况 iostat: 每个磁盘 I/O 的使用情况，由块设备接口报告 netstat: 网络接口统计 sar: 各种各样统计，能归档历史数据 iftop: 用来监控网卡的实时流量（可以指定网段）、反向解析IP、显示端口信息等 进程级别： ps：进程状态，显示进程的各种统计信息，包括内存和CPU的使用 top：按一个统计数据排序，显示排名高的进程 pmap：将进程的内存和使用统计一起列出 iotop: 进程的I/O速度 pidstat：每个进程/线程CPU使用量 一般来说，上述工具从/proc 文件系统里读取统计信息。 跟踪：系统级别： tcpdump：网络抓包(libpcap) bltrace: 块I/O 跟踪 dtrace: 跟踪内核的内部活动和所有资源的使用情况，支持静态和动态跟踪 perf: linux 性能事件，跟踪静态和动态的指针 进程级别： strace: 系统调用跟踪 gdb: 调式源码 网络工具： nethogs: 按进程查看流量占用 iptraf: 按连接/端口查看流量 ifstat: 按设备查看流量 ethtool: 诊断工具 tcpdump: 抓包工具 ss: 连接查看工具, 比netstat更快速更高效 其他: dstat, slurm, nload, bmon 第五章 应用程序性能调整离执行的地方越近越好：最好在应用程序里，包括web服务器、应用服务器、负载均衡、文件服务器等等 设立性能目标能为你的性能分析工作指明方向，并帮助你选择要做的事情。没有目标，性能分析容易沦为随机的[钓鱼探险]。常见目标： 延时 吞吐量 资源使用率 应用程序性能技术：选择I/O尺寸、缓存、缓冲区、轮询、并发和并行、非阻塞I/O、处理器绑定 编程语言相关：编译器优化、解释语言一般不是首选、虚拟机、垃圾回收 第六章 CPU 第七章 内存背景：内存相关术语架构：内存软硬件架构方法：内存分析的方法分析：分析内存性能工具调优：性能调优和可调参数范例 1.背景主存：物理内存，高速数据存储区域，动态随机访问内存(DRAM)虚拟内存: 一个抽象的主存概念，无限和非竞争性，虚拟内存不是真实的内存常驻内存：当前处于主存中的内存匿名内存: 无文件系统位置或者路径名的内存。包括进程地址空间的工作数据，称作堆。地址空间：内存上下文。每个进程和内核都有对应的虚拟内存空间段：标记为特殊用途的一块内存区域，例如用来存储可执行或者可写的页OOM：内存耗尽，内核检测到可用内存低页：操作系统和CPU使用的内存单位。一直以来都是4KB或8KB，现代处理器允许多种页大小。缺页：无效内存。使用按虚拟内存，这是正常事件。交换：将整个进程从主存转移到交换设备。交换(空间)：存放换页的匿名数据和交换进程的磁盘空间。可以是存储设备的一块空间， 也称为物理交换设备，或者是文件系统，称作交换文件。 换页：页面换入和调出主存。包含文件系统换页(mmap), 匿名换页(进程堆和栈) 按需换页：将虚拟内存映射到物理内存。CPU创建映射的开销延迟到实际需要或者访问。 过度换页：支持按需换页操作系统，malloc可以申请大于物理内存和交换设备的总和。 文件系统缓占用：应用进程需要时会释放 2.架构硬件：主存，总线，CPU缓存，MMU(内存管理单元)软件： 3.方法 第八章 文件系统 第九章 磁盘 第十章 网络]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[c++ 编程思想 笔记]]></title>
    <url>%2F2018%2F10%2F24%2Fc-%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3-%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPC框架原理和实践]]></title>
    <url>%2F2018%2F10%2F24%2FRPC%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[简单的RPC框架有三部分组成： 1 服务提供者，运行在服务端，负责提供服务接口定义和服务实现类2 服务发布者，运行在RPC服务端，负责将本地服务发布成远程服务，供其他消费者调用3 本地服务代理，运行在RPC客户端，通过代理调用远程服务提供者，然后将结果进行封返回给本地消费者 RPC框架的调用原理如图： 服务治理问题在大规模服务化之前，应用可能只是通过RPC框架，简单的暴露和引用远程服务，通过配置URL地址进行远程服务调用，路由则通过F5负载均衡器等进行简单的负载均衡。 当服务越来越多的时候，服务的URL配置管理变得更加困难。单纯的使用RPC就有点吃不消。所以在大规模分布式集群中，RPC只是作为集群的一个方法调用手段。 RPC框架实现的几个核心技术点： 远程服务提供者 需要以某种形式(url/idl)提供给服务调用者 远程代理对象 服务调用者调用的服务实际是远程服务的本地代理 通信： 与具体协议无关 序列化：远程通信需要将对象转成二进制进行传输，不同序列化框架，支持的数据类型数据包大小，及性能差异很大 PRC框架高性能设计 I/O调度模型：同步阻塞(BIO) 还是非阻塞(NIO) 序列化框架的选择：文本协议、二进制协议、压缩后的二进制协议 线程调度模型： 串行或是并行调度，锁竞争还是无锁化 实践消息定义Header: TaskCreateTime/TaskTimeOut/SessionId/TenantldBody: Session String/SDL stream/ErrorInfo 序列化根据不同的序列化框架做比对测试 框架版本 测试内容 处理次数 耗时(us) 每秒处理次数 每次耗时(us) 1.8.x SJSON序列化 10000 416,225 24,025 41.62 1.8.x SJSON反序列化 10000 581,872 17,185 58.19 2.1.0 SCDR序列化 500000 2,716,170 184,083 5.43 2.1.0 SCDR反序列化 500000 3,409,015 146,670 6.82 2.1.0 SJSON序列化 10000 1,145,281 8,731 115 2.1.0 SJSON反序列化 10000 954,927 10,472 95.5 2.2.0 SJSON序列化 10000 427225 23,407 42.72 2.2.0 SJSON反序列化 10000 505211 19,794 50.52 RPC服务端模型设计1 纯粹单线程模型 所有工作在一个线程里实现采用非阻塞I/O实现单线程处理能力最大化，但没有扩展能力适用于连接数少、负载轻的服务场景 2 独立事件轮询线程 + 工作线程组模型 独立的事件轮询线程工作线程可水平扩展（性能非线性扩展）线程间频繁数据交换需要同步机制影响性能工作线程一次只处理一个连接的任务，对于慢速连接效率不高（可能会被阻塞）适用于任务量不大但业务处理耗时较大、网速快且稳定等场景 3 独立端口监听 + I/O及工作线程组模型 独立端口监听线程，获取的新连接转发给指定的工作线程工作线程负责socket连接的I/O时间轮询，以及后续的消息I/O和业务处理采用非阻塞I/O，处理能力随工作线程的扩展而线性扩展适用于连接数大、任务量大但业务处理耗时较小的场景 4 独立端口监听 + I/O线程 + BIZ线程分组模型 I/O事件轮询和消息收发由独立I/O线程执行业务处理由独立线程执行并可扩展一个I/O线程和若干和BIZ线程组成一个线程组，并可按组横向扩展适用于连接数多，任务量大，任务处理耗时大的场景]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux 常用命令]]></title>
    <url>%2F2018%2F10%2F24%2Flinux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[系统级计数器vmstat虚拟内存和物理内存的统计 iostat每个磁盘 I/O 的使用情况，由块设备接口报告 mpstat每个CPU的使用情况 freesar 进程级计数器top1按一个统计数据排序，显示排名高的进程 ps123456789进程状态，显示进程的各种统计信息，包括内存和CPU的使用host-10-19-14-51:/data01/zjgrp/zjv8cs/sqlite&gt; ps -eLo pid,lwp,pcpu | grep 1256712567 12567 0.012567 12568 0.012567 12569 0.012567 12575 0.012567 12576 0.012567 12577 0.012567 12579 0.0 pmap将进程的内存和使用统计一起列出 iotop进程的I/O速度 pidstat查看进程I/O , 内存, CPU 网络工具netstatss1234567891011121314151617181920212223比netstat 效率高, 可以用time来比较-a, --all display all sockets-l, --listening display listening sockets-p, --processes show process using socket-s, --summary show socket usage summary-t, --tcp display only TCP sockets-u, --udp display only UDP sockets#列出来至120.33.31.1,80端口的连接ss src 120.33.31.1:httpss src 120.33.31.1:80host-10-19-14-51:/data01/zjgrp/zjv8cs&gt; ss -sTotal: 2701 (kernel 0)TCP: 2018 (estab 785, closed 1049, orphaned 0, synrecv 0, timewait 16/0), ports 0Transport Total IP IPv6* 0 - - RAW 0 0 0 UDP 1 1 0 TCP 969 831 138 INET 970 832 138 FRAG 0 0 0 iftop1用来监控网卡的实时流量（可以指定网段）、反向解析IP、显示端口信息等 nethogstpcdump 其他命令tarfinddu1234#显示当前文件下 Top 10 空间占用的文件/目录，#s 表示不显示每个子目录或文件的大小#h 表示用更加自然的方式显示（比如 K/M/G 这样）du -sh * | sort -nr | head ddlsof12# 查看进程打开文件lsof -p pid 常用技巧：12345678910111213141516cat file1 file2 &gt;file3 #合并文件tac file #以行为单位，倒序显示head -n 100 file #显示file的前100行head -n -100 file #显示file的除最后100行以外的内容。 tail -100 file #显示file最后100行内容tail -n +100 file #从第100行开始显示file内容 sed -n &apos;1,100p&apos; file &gt; file2 #截取file中1到100行到file2sed -n &quot;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&quot; file #显示包含&quot;&amp;&amp;&amp;&amp;&amp;&quot;行sort/uniq #文本排序date +%s #将当前时间转成Unix时间戳date -d &apos;2013-2-22 22:14&apos; +%s #指定日期转成Unix时间戳date -d @1361542596 +&quot;%Y-%m-%d %H:%M:%S&quot; #指定格式输出grep &apos;aaa\|bbb&apos; file #查询&amp;&amp;&amp;或$$$grep -v &apos;root&apos; file #查询不包含root的行ps -ef | grep gmake | grep –v root | awk &apos;&#123;print $2&#125;&apos; | xargs kill -9 # 杀进程echo &quot;password&quot; | passwd testuser --stdin # linux用shell修改密码]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Docker实践]]></title>
    <url>%2F2018%2F10%2F24%2FDocker%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[Docker 简介Docker 是什么 Docker 最初是dotCloud公司的一个内部项目 Docker 使用go语言开发实现 Docker 是操作系统层面的虚拟化技术 Docker 是在操作系统层面进行虚拟化, 直接复用本地主机操作系统; 而传统方式是在硬件层面实现。 为什么用 Docker优势 1更高效的利用系统资源(额外系统消耗忽略不计) 2更快速的启动时间(秒级启动, 比传统虚拟机快) 3一致的运行环境(开发、测试、生产环境一样) 4持续交付和部署(Docker构建镜像, 快速部署) 5更轻松的迁移(平台迁移方便) 6更轻松的维护和扩展(分层存储以及镜像技术, 复用和维护简单) 容器基本不消化额外的系统资源, 秒级启动, 性能很高. 启动十个进程, 需要启动10台虚拟机, 但Docker只需要启动十个隔离的应用即可。 基本概念 镜像(Image) 一个特殊的文件系统, 包含程序,库,配置文件 利用Union FS技术分层存储, 由多层文件系统联合组成, Dockerfile会一层层的构建 容器(Container) 容器是从镜像运行时的实例, 会在镜像基础上创建一个存储层用于读写, 生命周期和容器一样 可以启、停止、删除、暂停等。容器内的进程是隔离的, 容器有自己的网络,文件系统, 进程空间, 用户空间 仓库(Registy) 存放镜像的场所, 可以是公有仓库或者私有仓库 官方Docker Hub , 用阿里云加速, DaoCloud 等加速器下载更快 安装将Docker的用户加入到Docker用户组 $ groupadd docker$ usermod -aG docker $USER 使用镜像1 获取镜像 docker pull 2 列出镜像123456789101112131415161718192021222324252627billing-csv-jfzx08%docker imagesREPOSITORY TAG IMAGE ID CREATED SIZE20.26.38.47:5000/redo_java v27 90afb9850803 2 hours ago 2.85GB20.26.38.47:5000/suse12.2-jf 1.8.6 3c7f01d195d9 3 hours ago 9.14GB20.26.38.47:5000/suse12.2-zc 1.7.6 b9afcd1d062b 4 hours ago 12.3GB20.26.38.47:5000/suse12.2-jf &lt;none&gt; 18a1b4e851ba 6 hours ago 9.14GB20.26.38.47:5000/suse12.2-jf &lt;none&gt; c9ff12f7c392 6 hours ago 9.13GB20.26.38.47:5000/suse12.2-jf &lt;none&gt; 86973ecd7035 7 hours ago 9.13GB20.26.38.47:5000/suse12.2-zc &lt;none&gt; a6a565cc7cd5 2 days ago 12.3GB20.26.38.47:5000/redo_java v26 71f5c0a56a15 3 days ago 2.85GB20.26.38.47:5000/suse12.2-jf &lt;none&gt; 87bed11aa735 3 days ago 9.11GB20.26.38.47:5000/dse-suse-12.2 latest 9930a53d9861 3 days ago 4.9GB20.26.38.47:5000/suse12.2-inputxdr test5 17c4f034235b 4 days ago 3.45GB20.26.38.47:5000/inputxdr v69.17 3ea2e49542c6 4 days ago 1.65GB20.26.38.47:5000/suse12.2-decode 1.7.6 791cb433e4d0 5 days ago 5.5GB20.26.38.47:5000/suse12.2-xc 1.3.6 5e0f0814a1b4 5 days ago 5.29GB20.26.38.47:5000/suse12.2-csf 2.1 2542b7237ccb 6 days ago 3.57GB20.26.38.47:5000/suse12.2-zc 1.7.4 1ab625d2ea97 7 days ago 10.7GB20.26.38.47:5000/dse-suse-12.2 &lt;none&gt; b293ed18bbef 11 days ago 4.74GB20.26.38.47:5000/suse12.2-decode 1.7.4 b867b33eca4e 13 days ago 5.36GB20.26.38.47:5000/suse12.2-xc 1.3.4 5f7c56b09631 13 days ago 5.15GB20.26.38.47:5000/suse12.2-jf 1.8.4 c60a266497d9 13 days ago 7.66GB20.26.38.47:5000/dse-suse-12.2 &lt;none&gt; 67e18d4bf990 2 weeks ago 4.89GB20.26.28.55/acam/tomcat 8.5.29-jre8-alpine d6c75482e065 8 months ago 106MB20.26.28.55/acam/tomcat v1 d6c75482e065 8 months ago 106MB20.26.28.55/platformv8/tomcat 8.5.29-jre8-alpine d6c75482e065 8 months ago 106MBregistry.yw.zj.chinamobile.com/dcos/df-client 1.9 8f7837553678 10 months ago 276MB 包含了仓库, 标签, 镜像ID, 创建时间, 占用空间 镜像体积：上面命令显示的是展开后各层总和, 实际硬盘占用会小很多 123456billing-csv-jfzx08%docker system dfTYPE TOTAL ACTIVE SIZE RECLAIMABLEImages 23 16 30.06GB 25.58GB (85%)Containers 132 25 10.66MB 1.174MB (11%)Local Volumes 0 0 0B 0BBuild Cache 0B 0B 虚悬镜像： 旧版本被覆盖， docker image prune 删除 中间层镜像：docker image ls -a 列出部分或指定镜像:1234567891011121314151617billing-csv-jfzx08%docker image ls 20.26.38.47:5000/suse12.2-jf:1.8.4REPOSITORY TAG IMAGE ID CREATED SIZE20.26.38.47:5000/suse12.2-jf 1.8.4 c60a266497d9 13 days ago 7.66GBbilling-csv-jfzx08%docker image ls -f since=20.26.38.47:5000/redo_java:v26REPOSITORY TAG IMAGE ID CREATED SIZE20.26.38.47:5000/redo_java v27 90afb9850803 4 hours ago 2.85GB20.26.38.47:5000/suse12.2-jf 1.8.6 3c7f01d195d9 5 hours ago 9.14GB20.26.38.47:5000/suse12.2-zc 1.7.6 b9afcd1d062b 6 hours ago 12.3GB20.26.38.47:5000/suse12.2-jf &lt;none&gt; 18a1b4e851ba 7 hours ago 9.14GB20.26.38.47:5000/suse12.2-jf &lt;none&gt; c9ff12f7c392 8 hours ago 9.13GB20.26.38.47:5000/suse12.2-jf &lt;none&gt; 86973ecd7035 9 hours ago 9.13GB20.26.38.47:5000/suse12.2-zc &lt;none&gt; a6a565cc7cd5 2 days ago 12.3GB// 某个镜像之前的镜像, since 改成beforedocker imgae ls -qdocker image ls --format &quot;&#123;&#123;.ID&#125;&#125;:&#123;&#123;.Respository&#125;&#125;&quot; 3 删除本地镜像docker image rm $(docker image ls -q -f since=20.26.38.47:5000/redo_java:v26)docker ls –digests Dockerfile 实现原理 操作容器访问仓库数据管理网络]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分布式服务框架原理和实践]]></title>
    <url>%2F2018%2F10%2F24%2F%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据库事务及锁]]></title>
    <url>%2F2018%2F10%2F23%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1%E5%8F%8A%E9%94%81%2F</url>
    <content type="text"><![CDATA[事务的四个特性 原子性(Atomicity) 一致性(Consistency) 隔离性(Isolation) 持久性(Durability) 原子性一个事务中的全部操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会回滚到事务开始前的状态，不会对数据库有任何影响。 一致性在事务开始之前和事务结束以后，数据库的完整性没有被破坏。拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。 隔离性数据库允许多个并发事务对数据进行读写和修改，防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交(Read uncommitted)、读提交(read committed)、可重复读(repeatable read)和串行化（Serializable）。即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。 持久性事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 事务隔离级别如果不考虑事务的隔离性，会发生的几种问题: 脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。(读未提交) 不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。 虚读(幻读)幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户, 如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。幻读和不可重复读都是读取了另一条已经提交的事务(这点就脏读不同)，所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体(比如数据的个数)。 串行化(Serializable)在串行化隔离模式下，消除了脏读，幻象，但事务并发度急剧下降，事务的隔离级别与事务的并发度成反比，隔离级别越高，事务的并发度越低。实际生产环境下，dba会在并发和满足业务需求之间作权衡，选择合适的隔离级别 现在来看看MySQL数据库为我们提供的四种隔离级别： ① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。 ② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。 ③ Read committed (读已提交)：可避免脏读的发生。 ④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。 在MySQL数据库中，支持上面四种隔离级别，默认的为Repeatable read (可重复读)；而在Oracle数据库中，只支持Serializable (串行化)级别和Read committed (读已提交)这两种级别，其中默认的为Read committed级别 事务隔离的实现——锁 共享锁(S锁) [] 用于只读操作(SELECT)，锁定共享的资源。共享锁不会阻止其他用户读，但是阻止其他的用户写和修改。 更新锁(U锁) [] 用于可更新的资源中。防止当多个会话在读取、锁定以及随后可能进行的资源更新时发生常见形式的死锁。 独占锁(X锁，也叫排他锁) [] 一次只能有一个独占锁用在一个资源上，并且阻止其他所有的锁包括共享缩。写是独占锁，可以有效的防止“脏读”。 Read Uncommited 如果一个事务已经开始写数据，则另外一个数据则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现。 Read Committed 读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。可以通过“瞬间共享读锁”和“排他写锁”实现。 Repeatable Read 读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。可以通过“共享读锁”和“排他写锁”实现。 Serializable 读加共享锁，写加排他锁，读写互斥。 三级封锁协议mvcc多版本并发控制协议间隙锁]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>ACID</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux知识体系]]></title>
    <url>%2F2018%2F10%2F19%2Flinux%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[c++知识体系]]></title>
    <url>%2F2018%2F10%2F19%2Fc-%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>c++</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[gdb多线程调试]]></title>
    <url>%2F2018%2F10%2F15%2Fgdb%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%B0%83%E8%AF%95-1%2F</url>
    <content type="text"><![CDATA[all-stop mode: 默认模式, 有一个线程在断点处停止，其他所有线程也会停止 non-stop mode: 某一个线程停止时，其他线程会继续运行 Background Execution：异步运行程序 Thread-Specific Breakpoints: 控制断点 Interrupted System Calls: gdb会干扰系统调用 Observer Mode：gdb不影响程序执行 all-stop mode当进程在gdb下停止时，所有的线程都停止运行。当用单步调试命令“step或next”，所有的线程开始执行。由于执行线程调度的是操作系统不是gdb，单步调试命令不能让所有的线程都单步。当前线程执行了一步，其他线程可能执行了N步。当执行next/step/continue时，当前线程完成单步运行前，其他线程运行遇到断点/信号/异常，gdb会选择一个遇到短信或信号中断的线程，切换线程时会提示“[Switching to Thread n]” set scheduler-locking设置调度锁定模式，在一些系统中，gdb可以通过锁定操作系统线程调度，只允许一个线程运行。如果是on,单步调试命令会阻止其他线程抢占, 其他线程不会运行。如果是off，所有线程线程都会运行。当执行continue/util/finish 时，其他进程会恢复运行. show scheduler-locking显示当前线程调度锁定状态 set schedule-multiple当执行continue/next/step时，gdb只允许当前进程下的线程恢复运行(fork出过个进程)。on: 所有进程下的线程恢复运行off: 当前进程下的线程恢复运行 show schedule-multiple显示多进程恢复模式 non-stop mode在一些多线程的应用中，gdb支持只停止需要调试的线程，其他线程可运行不受影响。例如某些线程具有实时约束或必须继续响应外部事件，这是最小化的实时调试。称为不间断模式。在non-stop mode中，当一个线程因为断点停止时，其他线程正常运行，continue/step 只适用于当前线程。一般情况下在gdb启动或attach 一个进程时设置non-stop mode, 顺序执行如下命令，进入non-stop mode: Enable the async interface. set target-async 1 If using the CLI, pagination breaks non-stop. set pagination off Finally, turn it on! set non-stop on continue -a, 让所有线程都继续执行, continue 只能让当前线程继续执行interrupt -a, 停止整个程序, interrupt/Ctrl-c 只能让当前线程挂起, 其他命令不支持-a. Background Execution基本上用不到 Thread-Specific Breakpointsbreak linespec thread threadnobreak linespec thread threadno if ..threadno 从 info threads 中得到.比如(gdb) break frik.c:13 thread 28 if bartab &gt; lim [ ] Interrupted System Calls在使用gdb调试多线程程序时，有一个副作用。如果一个线程因断点或其他原因而停止，而另一个线程在系统调用中被阻塞，那么系统调用可能会提前返回。这是多线程和gdb用来实现断点和其他停止执行的事件的信号之间交互的结果。例如： sleep (10); 如果不同的线程在断点处或出于其他原因停止，则调用sleep将提前返回。 int unslept = 10; while (unslept &gt; 0) unslept = sleep (unslept); 允许系统调用提前返回，因此系统仍然符合其规范。但是gdb确实会导致多线程程序的行为与没有gdb时不同。另外，gdb在线程库中使用内部断点来监视某些事件，例如线程创建和线程销毁。当这样的事件发生时，另一个线程中的系统调用可能会提前返回，即使您的程序似乎没有停止. Observer Mode略]]></content>
      <categories>
        <category>gdb</category>
      </categories>
      <tags>
        <tag>gdb</tag>
      </tags>
  </entry>
</search>
